# final_complete_with_chinese.py
"""
æœ€ç»ˆå®Œæ•´å®éªŒè„šæœ¬ - ä¿®å¤ä¸­æ–‡æ˜¾ç¤ºå’Œå¢å¼ºæ”»å‡»æ•ˆæœï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰
"""

import os
import sys
import torch
import numpy as np
import jieba
import warnings
import pandas as pd
import re
warnings.filterwarnings('ignore')

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), 'src'))

def run_final_complete_experiment():
    print("=" * 80)
    print("å¯¹æŠ—æ€§æ•°æ®æ”¹å†™åœ¨æ¬ºè¯ˆå¯¹è¯æ£€æµ‹ä¸­çš„åº”ç”¨ - å®Œæ•´ä¿®å¤ç‰ˆ")
    print("ä½œè€…: è©¹å®¶æƒ  (2023152005)")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    # è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡
    import matplotlib
    matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
    matplotlib.rcParams['axes.unicode_minus'] = False    # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
    
    # å¯¼å…¥å¿…è¦æ¨¡å—
    try:
        from src.models import ModelManager
        from transformers import BertTokenizer
        import ssl
        ssl._create_default_https_context = ssl._create_unverified_context
        print("âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âœ— æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return
    
    # 1. åŠ è½½ç°æœ‰æ•°æ®é›†
    print("\n[1/7] åŠ è½½ç°æœ‰æ•°æ®é›†...")
    
    # ç¡®ä¿dataæ–‡ä»¶å¤¹å­˜åœ¨
    data_dir = "data"
    if not os.path.exists(data_dir):
        print(f"âœ— æ•°æ®æ–‡ä»¶å¤¹ '{data_dir}' ä¸å­˜åœ¨")
        return
    
    train_file = os.path.join(data_dir, "è®­ç»ƒé›†ç»“æœ.csv")
    test_file = os.path.join(data_dir, "æµ‹è¯•é›†ç»“æœ.csv")
    
    if not os.path.exists(train_file):
        print(f"âœ— è®­ç»ƒé›†æ–‡ä»¶ '{train_file}' ä¸å­˜åœ¨")
        return
    
    if not os.path.exists(test_file):
        print(f"âœ— æµ‹è¯•é›†æ–‡ä»¶ '{test_file}' ä¸å­˜åœ¨")
        return
    
    try:
        # è¯»å–è®­ç»ƒé›†
        train_df = pd.read_csv(train_file)
        print(f"âœ“ è®­ç»ƒé›†åŠ è½½æˆåŠŸ: {len(train_df)} æ¡è®°å½•")
        
        # è¯»å–æµ‹è¯•é›†
        test_df = pd.read_csv(test_file)
        print(f"âœ“ æµ‹è¯•é›†åŠ è½½æˆåŠŸ: {len(test_df)} æ¡è®°å½•")
        
        # æå–æ–‡æœ¬å’Œæ ‡ç­¾
        text_col = 'specific_dialogue_content'
        label_col = 'is_fraud'
        
        if text_col not in train_df.columns:
            text_candidates = [col for col in train_df.columns if any(word in col.lower() for word in ['content', 'å¯¹è¯', 'text', 'dialogue', 'message'])]
            if text_candidates:
                text_col = text_candidates[0]
                print(f"  â†’ ä½¿ç”¨åˆ— '{text_col}' ä½œä¸ºæ–‡æœ¬åˆ—")
            else:
                print(f"âœ— æ‰¾ä¸åˆ°åˆé€‚çš„æ–‡æœ¬åˆ—")
                return
        
        if label_col not in train_df.columns:
            label_candidates = [col for col in train_df.columns if any(word in col.lower() for word in ['fraud', 'æ¬ºè¯ˆ', 'label', 'is_fraud', 'flag'])]
            if label_candidates:
                label_col = label_candidates[0]
                print(f"  â†’ ä½¿ç”¨åˆ— '{label_col}' ä½œä¸ºæ ‡ç­¾åˆ—")
            else:
                print(f"âœ— æ‰¾ä¸åˆ°åˆé€‚çš„æ ‡ç­¾åˆ—")
                return
        
        print(f"  ä½¿ç”¨åˆ— '{text_col}' ä½œä¸ºæ–‡æœ¬å†…å®¹")
        print(f"  ä½¿ç”¨åˆ— '{label_col}' ä½œä¸ºæ ‡ç­¾")
        
        # ä½¿ç”¨éƒ¨åˆ†æ•°æ®è¿›è¡Œå¿«é€Ÿå®éªŒ
        SAMPLE_RATIO = 0.2
        np.random.seed(42)
        
        # å¯¹è®­ç»ƒé›†é‡‡æ ·
        train_sample_size = int(len(train_df) * SAMPLE_RATIO)
        train_indices = np.random.choice(len(train_df), train_sample_size, replace=False)
        train_sample = train_df.iloc[train_indices]
        
        # å¯¹æµ‹è¯•é›†é‡‡æ ·
        test_sample_size = int(len(test_df) * SAMPLE_RATIO)
        test_indices = np.random.choice(len(test_df), test_sample_size, replace=False)
        test_sample = test_df.iloc[test_indices]
        
        # æå–é‡‡æ ·åçš„æ–‡æœ¬
        train_texts = train_sample[text_col].astype(str).tolist()
        test_texts = test_sample[text_col].astype(str).tolist()
        
        # è½¬æ¢æ ‡ç­¾
        def convert_labels(label_series):
            labels = []
            for label in label_series:
                if isinstance(label, bool):
                    labels.append(1 if label else 0)
                elif isinstance(label, (int, float)):
                    labels.append(1 if label == 1 or label == 1.0 else 0)
                elif isinstance(label, str):
                    label_lower = label.lower().strip()
                    if label_lower in ['true', 't', 'yes', 'y', '1', 'æ˜¯', 'æ¬ºè¯ˆ', 'fraud', 'çœŸ']:
                        labels.append(1)
                    else:
                        labels.append(0)
                else:
                    labels.append(0)
            return labels
        
        train_labels = convert_labels(train_sample[label_col])
        test_labels = convert_labels(test_sample[label_col])
        
        print(f"\nğŸ“Š æ•°æ®é‡‡æ ·ä¿¡æ¯:")
        print(f"  é‡‡æ ·æ¯”ä¾‹: {SAMPLE_RATIO:.0%}")
        print(f"  è®­ç»ƒé›†é‡‡æ ·: {len(train_texts)}/{len(train_df)} æ¡")
        print(f"  æµ‹è¯•é›†é‡‡æ ·: {len(test_texts)}/{len(test_df)} æ¡")
        print(f"  è®­ç»ƒé›†æ ‡ç­¾ - æ¬ºè¯ˆ({sum(train_labels)}), æ­£å¸¸({len(train_labels)-sum(train_labels)})")
        print(f"  æµ‹è¯•é›†æ ‡ç­¾ - æ¬ºè¯ˆ({sum(test_labels)}), æ­£å¸¸({len(test_labels)-sum(test_labels)})")
        
        # æ˜¾ç¤ºæ ·æœ¬ç¤ºä¾‹
        print("\næ ·æœ¬ç¤ºä¾‹:")
        for i in range(min(2, len(train_texts))):
            clean_text = train_texts[i].replace('\n', ' ').replace('\r', '')
            text_preview = clean_text[:40] + "..." if len(clean_text) > 40 else clean_text
            print(f"  æ ·æœ¬{i+1}: {text_preview}")
            print(f"      æ ‡ç­¾: {'æ¬ºè¯ˆ' if train_labels[i]==1 else 'æ­£å¸¸'}")
    
    except Exception as e:
        print(f"âœ— åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # åˆ›å»ºé…ç½®ï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
    config = {
        'models': {
            'bert': {
                'model_name': 'bert-base-chinese',
                'max_length': 96,
                'learning_rate': 2e-5,
                'dropout': 0.3
            },
            'bilstm': {
                'embedding_dim': 200,
                'hidden_dim': 128,
                'num_layers': 1,
                'dropout': 0.3,
                'max_length': 96,
                'learning_rate': 1e-3
            }
        },
        'experiment': {
            'device': 'cpu',
            'batch_size': 16,
            'num_epochs': 3
        }
    }
    
    device = torch.device('cpu')
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    # å®éªŒç»“æœå­˜å‚¨
    results = {}
    
    # 2. è®­ç»ƒBERTæ¨¡å‹
    print("\n[2/7] è®­ç»ƒBERTæ¨¡å‹...")
    
    model_manager = ModelManager(config, device)
    
    try:
        bert_model, bert_tokenizer = model_manager.initialize_model('bert', num_classes=2)
        print("âœ“ BERTæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âœ— BERTæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from torch.utils.data import Dataset, DataLoader
    
    class BertDataset(Dataset):
        def __init__(self, texts, labels, tokenizer, max_length=96):
            self.texts = texts
            self.labels = labels
            self.tokenizer = tokenizer
            self.max_length = max_length
        
        def __len__(self):
            return len(self.texts)
        
        def __getitem__(self, idx):
            text = str(self.texts[idx]).replace('\n', ' ').replace('\r', '')
            label = self.labels[idx]
            
            encoding = self.tokenizer(
                text,
                truncation=True,
                padding='max_length',
                max_length=self.max_length,
                return_tensors='pt'
            )
            
            return {
                'input_ids': encoding['input_ids'].flatten(),
                'attention_mask': encoding['attention_mask'].flatten(),
                'labels': torch.tensor(label, dtype=torch.long)
            }
    
    bert_train_dataset = BertDataset(train_texts, train_labels, bert_tokenizer)
    bert_test_dataset = BertDataset(test_texts, test_labels, bert_tokenizer)
    
    bert_train_loader = DataLoader(bert_train_dataset, batch_size=16, shuffle=True)
    bert_test_loader = DataLoader(bert_test_dataset, batch_size=16, shuffle=False)
    
    # è®­ç»ƒBERT
    criterion = torch.nn.CrossEntropyLoss()
    bert_optimizer = torch.optim.AdamW(bert_model.parameters(), lr=2e-5)
    
    best_bert_acc = 0
    bert_history = {'train_acc': [], 'test_acc': []}
    
    print("â³ BERTè®­ç»ƒä¸­...")
    for epoch in range(3):
        # è®­ç»ƒ
        bert_model.train()
        train_correct = 0
        train_total = 0
        
        for batch_idx, batch in enumerate(bert_train_loader):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            bert_optimizer.zero_grad()
            outputs = bert_model(input_ids, attention_mask)
            loss = criterion(outputs, labels)
            loss.backward()
            bert_optimizer.step()
            
            _, predicted = torch.max(outputs, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()
        
        train_acc = train_correct / train_total if train_total > 0 else 0
        bert_history['train_acc'].append(train_acc)
        
        # æµ‹è¯•
        bert_model.eval()
        test_correct = 0
        test_total = 0
        
        with torch.no_grad():
            for batch in bert_test_loader:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['labels'].to(device)
                
                outputs = bert_model(input_ids, attention_mask)
                _, predicted = torch.max(outputs, 1)
                test_total += labels.size(0)
                test_correct += (predicted == labels).sum().item()
        
        test_acc = test_correct / test_total if test_total > 0 else 0
        bert_history['test_acc'].append(test_acc)
        
        print(f"Epoch {epoch+1}/3: è®­ç»ƒå‡†ç¡®ç‡={train_acc:.4f}, æµ‹è¯•å‡†ç¡®ç‡={test_acc:.4f}")
        
        if test_acc > best_bert_acc:
            best_bert_acc = test_acc
            os.makedirs('models', exist_ok=True)
            torch.save(bert_model.state_dict(), "models/bert_final.pth")
    
    results['bert_baseline'] = best_bert_acc
    results['bert_history'] = bert_history
    print(f"âœ“ BERTæ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_bert_acc:.4f}")
    
    # 3. è®­ç»ƒBiLSTMæ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    print("\n[3/7] è®­ç»ƒBiLSTMæ¨¡å‹...")
    
    try:
        # æ„å»ºè¯æ±‡è¡¨
        all_words = []
        for text in train_texts[:500]:
            all_words.extend(jieba.lcut(str(text)))
        
        from collections import Counter
        word_counter = Counter(all_words)
        vocab = {word: idx+1 for idx, (word, _) in enumerate(word_counter.most_common(1000))}
        vocab['<PAD>'] = 0
        vocab['<UNK>'] = len(vocab)
        
        # BiLSTMæ¨¡å‹
        bilstm_model, _ = model_manager.initialize_model('bilstm', vocab_size=len(vocab), num_classes=2)
        
        class BiLSTMTokenizer:
            def __init__(self, vocab):
                self.vocab = vocab
            
            def __call__(self, text, **kwargs):
                text_str = str(text).replace('\n', ' ').replace('\r', '')
                words = jieba.lcut(text_str)
                ids = [self.vocab.get(word, self.vocab['<UNK>']) for word in words]
                return {'input_ids': torch.tensor(ids, dtype=torch.long)}
        
        bilstm_tokenizer = BiLSTMTokenizer(vocab)
        
        class BiLSTMDataset(Dataset):
            def __init__(self, texts, labels, tokenizer, max_length=96):
                self.texts = texts
                self.labels = labels
                self.tokenizer = tokenizer
                self.max_length = max_length
            
            def __len__(self):
                return len(self.texts)
            
            def __getitem__(self, idx):
                encoding = self.tokenizer(str(self.texts[idx]))
                input_ids = encoding['input_ids']
                
                if len(input_ids) > self.max_length:
                    input_ids = input_ids[:self.max_length]
                elif len(input_ids) < self.max_length:
                    pad_size = self.max_length - len(input_ids)
                    input_ids = torch.cat([input_ids, torch.zeros(pad_size, dtype=torch.long)])
                
                return {
                    'input_ids': input_ids,
                    'labels': torch.tensor(self.labels[idx], dtype=torch.long)
                }
        
        # ä½¿ç”¨æ›´å°‘æ•°æ®è®­ç»ƒBiLSTM
        bilstm_sample_size = min(500, len(train_texts))
        bilstm_train_dataset = BiLSTMDataset(train_texts[:bilstm_sample_size], train_labels[:bilstm_sample_size], bilstm_tokenizer)
        bilstm_test_dataset = BiLSTMDataset(test_texts[:min(200, len(test_texts))], test_labels[:min(200, len(test_labels))], bilstm_tokenizer)
        
        bilstm_train_loader = DataLoader(bilstm_train_dataset, batch_size=16, shuffle=True)
        bilstm_test_loader = DataLoader(bilstm_test_dataset, batch_size=16, shuffle=False)
        
        # è®­ç»ƒBiLSTM
        bilstm_optimizer = torch.optim.Adam(bilstm_model.parameters(), lr=1e-3)
        best_bilstm_acc = 0
        
        print("â³ BiLSTMè®­ç»ƒä¸­...")
        for epoch in range(2):
            # è®­ç»ƒ
            bilstm_model.train()
            train_correct = 0
            train_total = 0
            
            for batch in bilstm_train_loader:
                input_ids = batch['input_ids'].to(device)
                labels = batch['labels'].to(device)
                
                bilstm_optimizer.zero_grad()
                outputs = bilstm_model(input_ids)
                loss = criterion(outputs, labels)
                loss.backward()
                bilstm_optimizer.step()
                
                _, predicted = torch.max(outputs, 1)
                train_total += labels.size(0)
                train_correct += (predicted == labels).sum().item()
            
            train_acc = train_correct / train_total if train_total > 0 else 0
            
            # æµ‹è¯•
            bilstm_model.eval()
            test_correct = 0
            test_total = 0
            
            with torch.no_grad():
                for batch in bilstm_test_loader:
                    input_ids = batch['input_ids'].to(device)
                    labels = batch['labels'].to(device)
                    
                    outputs = bilstm_model(input_ids)
                    _, predicted = torch.max(outputs, 1)
                    test_total += labels.size(0)
                    test_correct += (predicted == labels).sum().item()
            
            test_acc = test_correct / test_total if test_total > 0 else 0
            
            print(f"Epoch {epoch+1}/2: è®­ç»ƒå‡†ç¡®ç‡={train_acc:.4f}, æµ‹è¯•å‡†ç¡®ç‡={test_acc:.4f}")
            
            if test_acc > best_bilstm_acc:
                best_bilstm_acc = test_acc
        
        results['bilstm_baseline'] = best_bilstm_acc
        print(f"âœ“ BiLSTMæ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_bilstm_acc:.4f}")
        
    except Exception as e:
        print(f"âš  BiLSTMè®­ç»ƒè·³è¿‡: {e}")
        results['bilstm_baseline'] = 0.0
    
    # 4. å¢å¼ºçš„å¯¹æŠ—æ”»å‡»å®éªŒ
    print("\n[4/7] è¿›è¡Œå¢å¼ºçš„å¯¹æŠ—æ”»å‡»å®éªŒ...")
    
    # æ¿€è¿›çš„å…³é”®è¯æ›¿æ¢è¡¨
    aggressive_synonyms = {
        'é“¶è¡Œ': ['ç½‘ç»œå¹³å°', 'åœ¨çº¿æœåŠ¡', 'æ•°å­—æœºæ„', 'äº’è”ç½‘å…¬å¸', 'é‡‘èåº”ç”¨'],
        'å®¢æœ': ['æœºå™¨äºº', 'è‡ªåŠ¨åŠ©æ‰‹', 'æ™ºèƒ½ç³»ç»Ÿ', 'AIåŠ©æ‰‹', 'æœåŠ¡ç¨‹åº'],
        'éªŒè¯ç ': ['è¯†åˆ«ç¼–å·', 'ç¡®è®¤å·ç ', 'å®‰å…¨ç¼–å·', 'è®¤è¯ä»£ç ', 'éªŒè¯æ•°å­—'],
        'è½¬è´¦': ['èµ„é‡‘æ“ä½œ', 'æ¬¾é¡¹å¤„ç†', 'é‡‘é¢è½¬ç§»', 'è´¢åŠ¡è°ƒæ•´', 'æ±‡æ¬¾æ“ä½œ'],
        'è´·æ¬¾': ['èµ„é‡‘æ”¯æŒ', 'è´¢åŠ¡æ´åŠ©', 'ç»æµå¸®åŠ©', 'ä¿¡ç”¨æ”¯æŒ', 'å€Ÿæ¬¾æœåŠ¡'],
        'å¯†ç ': ['è®¿é—®å¯†é’¥', 'å®‰å…¨å£ä»¤', 'éšç§ä»£ç ', 'èº«ä»½å¯†ç ', 'ç™»å½•å¯†é’¥'],
        'èº«ä»½è¯': ['ä¸ªäººè¯ä»¶', 'èº«ä»½æ–‡ä»¶', 'IDè¯æ˜', 'è®¤è¯è¯ä»¶', 'èº«ä»½å‡­è¯'],
        'æŠ•èµ„': ['èµ„æºé…ç½®', 'èµ„äº§ç®¡ç†', 'èµ„é‡‘å®‰æ’', 'è´¢å¯Œè§„åˆ’', 'ç†è´¢æ“ä½œ'],
        'ä¸­å¥–': ['å¹¸è¿è·å¥–', 'æ´»åŠ¨è·å¥–', 'æŠ½é€‰è·å¥–', 'å¹¸è¿ä¸­é€‰', 'è·å¥–é€šçŸ¥'],
        'å…¬å®‰å±€': ['å®‰å…¨éƒ¨é—¨', 'ä¿æŠ¤æœºæ„', 'æ²»å®‰å•ä½', 'å…¬å®‰æœºæ„', 'è­¦å¯Ÿéƒ¨é—¨'],
        'æ¶‰å«Œ': ['å¯èƒ½å­˜åœ¨', 'æˆ–è®¸æ¶‰åŠ', 'å¯èƒ½å…³è”', 'ç–‘ä¼¼æœ‰å…³', 'æˆ–è®¸å­˜åœ¨'],
        'æ´—é’±': ['èµ„é‡‘é—®é¢˜', 'è´¢åŠ¡å¼‚å¸¸', 'æ¬¾é¡¹ç–‘é—®', 'èµ„é‡‘ç–‘æƒ‘', 'è´¢åŠ¡é—®é¢˜'],
        'å·¥å•†é“¶è¡Œ': ['å·¥è¡ŒæœåŠ¡', 'å·¥å•†é‡‘è', 'å·¥é“¶å¹³å°', 'å·¥å•†æœåŠ¡'],
        'å»ºè®¾é“¶è¡Œ': ['å»ºè¡ŒæœåŠ¡', 'å»ºè®¾é‡‘è', 'å»ºé“¶å¹³å°', 'å»ºè®¾æœåŠ¡'],
        'ä¸­å›½é“¶è¡Œ': ['ä¸­è¡ŒæœåŠ¡', 'ä¸­å›½é‡‘è', 'ä¸­é“¶å¹³å°', 'ä¸­å›½æœåŠ¡'],
        'æ‰‹ç»­è´¹': ['æœåŠ¡è´¹ç”¨', 'å¤„ç†è´¹ç”¨', 'æ“ä½œè´¹ç”¨', 'æ‰‹ç»­æˆæœ¬', 'æœåŠ¡æˆæœ¬'],
        'ç«‹å³': ['å°½å¿«', 'é©¬ä¸Š', 'å³åˆ»', 'ç«‹å³è¡ŒåŠ¨', 'è¿…é€Ÿ'],
        'éœ€è¦': ['è¦æ±‚', 'éœ€æ±‚', 'å¿…é¡»', 'åŠ¡å¿…', 'å¾—'],
        'æä¾›': ['ç»™äºˆ', 'å‘é€', 'æäº¤', 'ä¼ é€', 'å‘æ¥']
    }
    
    def enhanced_aggressive_attack(text, strategy='strong'):
        """çœŸæ­£æœ‰æ•ˆçš„æ”»å‡»ç­–ç•¥"""
        text_str = str(text).replace('\n', ' ').replace('\r', '')
        
        # æå–å¯¹è¯å†…å®¹
        clean_text = text_str
        if "éŸ³é¢‘å†…å®¹ï¼š" in clean_text:
            clean_text = clean_text.split("éŸ³é¢‘å†…å®¹ï¼š", 1)[-1].strip()
        
        if strategy == 'weak':
            # å¼±æ”»å‡»ï¼šä»…æ›¿æ¢1-2ä¸ªå…³é”®è¯
            words = jieba.lcut(clean_text)
            new_words = []
            replacements = 0
            
            for word in words:
                if word in aggressive_synonyms and replacements < 2 and np.random.random() < 0.5:
                    new_words.append(np.random.choice(aggressive_synonyms[word]))
                    replacements += 1
                else:
                    new_words.append(word)
            
            result = ''.join(new_words)
            if clean_text != text_str:
                return text_str.replace(clean_text, result)
            return result
        
        elif strategy == 'medium':
            # ä¸­æ”»å‡»ï¼šæ›¿æ¢å…³é”®è¯+ä¿®æ”¹å¥å­ç»“æ„
            words = jieba.lcut(clean_text)
            
            # æ›¿æ¢å…³é”®è¯
            new_words = []
            for word in words:
                if word in aggressive_synonyms and np.random.random() < 0.4:
                    new_words.append(np.random.choice(aggressive_synonyms[word]))
                elif word in ['éœ€è¦', 'è¦æ±‚', 'åŠ¡å¿…']:
                    new_words.append('å»ºè®®' if np.random.random() < 0.5 else 'å¯ä»¥')
                elif word in ['ç«‹å³', 'é©¬ä¸Š', 'ç«‹åˆ»']:
                    new_words.append('ç¨å' if np.random.random() < 0.5 else 'ä¹‹å')
                else:
                    new_words.append(word)
            
            result = ''.join(new_words)
            
            # æ·»åŠ ç–‘é—®æˆ–å¦å®š
            if np.random.random() < 0.5:
                doubt_phrases = ['è¯·é—®è¿™éœ€è¦æ”¶è´¹å—ï¼Ÿ', 'æˆ‘éœ€è¦æ ¸å®ä¸€ä¸‹ã€‚', 'è¿™ä¸ªå®‰å…¨å—ï¼Ÿ']
                if len(result) > 20:
                    insert_pos = np.random.randint(len(result)//4, 3*len(result)//4)
                    result = result[:insert_pos] + np.random.choice(doubt_phrases) + result[insert_pos:]
            
            if clean_text != text_str:
                return text_str.replace(clean_text, result)
            return result
        
        elif strategy == 'strong':
            # å¼ºæ”»å‡»ï¼šæ¿€è¿›æ”¹å†™
            is_fraud_keywords = any(word in clean_text for word in ['é“¶è¡Œ', 'å®¢æœ', 'éªŒè¯ç ', 'è½¬è´¦', 'è´·æ¬¾', 'ä¸­å¥–', 'å…¬å®‰å±€', 'æ´—é’±', 'æ¶‰å«Œ'])
            
            if is_fraud_keywords:
                # æ¬ºè¯ˆå¯¹è¯ -> æ”¹å†™ä¸ºæ­£å¸¸å¯¹è¯
                fraud_patterns = [
                    (r'é“¶è¡Œ.*?å®¢æœ.*?è´·æ¬¾', 'ç”µå•†å®¢æœå’¨è¯¢è®¢å•é—®é¢˜'),
                    (r'ä¸­å¥–.*?å¥–é‡‘.*?æ‰‹ç»­è´¹', 'ä¼šå‘˜ç§¯åˆ†å¯ä»¥å…‘æ¢ç¤¼å“'),
                    (r'å…¬å®‰å±€.*?æ¶‰å«Œ.*?æ´—é’±', 'ç¤¾åŒºé€šçŸ¥å®‰å…¨æ³¨æ„äº‹é¡¹'),
                    (r'éªŒè¯ç .*?èº«ä»½.*?æ ¸å®', 'ç™»å½•éªŒè¯éœ€è¦ç¡®è®¤ä¿¡æ¯'),
                    (r'æŠ•èµ„.*?é«˜æ”¶ç›Š.*?è½¬è´¦', 'ç†è´¢äº§å“æ”¶ç›Šç¨³å®šé€‚åˆé•¿æœŸæŒæœ‰'),
                    (r'éœ€è¦.*?æä¾›.*?å¯†ç ', 'å»ºè®®æ‚¨è®¾ç½®å¼ºå¯†ç '),
                    (r'ç«‹å³.*?è½¬è´¦.*?å®‰å…¨è´¦æˆ·', 'å»ºè®®é€šè¿‡æ­£è§„æ¸ é“æ“ä½œ')
                ]
                
                for pattern, replacement in fraud_patterns:
                    if re.search(pattern, clean_text, re.IGNORECASE):
                        result = re.sub(pattern, replacement, clean_text, flags=re.IGNORECASE)
                        if clean_text != text_str:
                            return text_str.replace(clean_text, result)
                        return result
                
                # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿›è¡Œæ¿€è¿›å…³é”®è¯æ›¿æ¢
                words = jieba.lcut(clean_text)
                new_words = []
                for word in words:
                    if word in aggressive_synonyms:
                        new_words.append(np.random.choice(aggressive_synonyms[word]))
                    elif word in ['éœ€è¦', 'è¦æ±‚', 'åŠ¡å¿…']:
                        new_words.append('å»ºè®®' if np.random.random() < 0.5 else 'å¯ä»¥')
                    elif word in ['ç«‹å³', 'é©¬ä¸Š', 'ç«‹åˆ»']:
                        new_words.append('ç¨å' if np.random.random() < 0.5 else 'ä¹‹å')
                    elif word in ['å®‰å…¨', 'ä¿éšœ']:
                        new_words.append('æ³¨æ„' if np.random.random() < 0.5 else 'å°å¿ƒ')
                    else:
                        new_words.append(word)
                
                result = ''.join(new_words)
                
                # æ·»åŠ å®‰å…¨å»ºè®®
                safety_notes = [
                    'å»ºè®®æ‚¨é€šè¿‡å®˜æ–¹æ¸ é“æ ¸å®ã€‚',
                    'è¯·è°¨æ…å¯¹å¾…æ­¤ç±»ä¿¡æ¯ã€‚',
                    'å»ºè®®è”ç³»å®˜æ–¹å®¢æœç¡®è®¤ã€‚',
                    'è¯·æ³¨æ„ä¿æŠ¤ä¸ªäººä¿¡æ¯å®‰å…¨ã€‚'
                ]
                if len(result) > 30:
                    result = result + ' ' + np.random.choice(safety_notes)
                
                if clean_text != text_str:
                    return text_str.replace(clean_text, result)
                return result
            else:
                # æ­£å¸¸å¯¹è¯ -> æ·»åŠ å¯ç–‘å†…å®¹
                normal_to_suspicious = [
                    (r'å¤–å–.*?é€é¤', 'é“¶è¡Œé€šçŸ¥è´¦æˆ·éœ€è¦éªŒè¯'),
                    (r'å¿«é€’.*?ç‰©æµ', 'ä¸­å¥–é€šçŸ¥éœ€è¦é¢†å–'),
                    (r'é…’åº—.*?é¢„è®¢', 'æŠ•èµ„æœºä¼šé«˜å›æŠ¥'),
                    (r'ä»·æ ¼.*?å’¨è¯¢', 'æ¶‰å«Œæ“ä½œéœ€è¦é…åˆè°ƒæŸ¥'),
                    (r'å’¨è¯¢.*?å®¢æœ', 'ç³»ç»Ÿæ£€æµ‹åˆ°è´¦æˆ·å¼‚å¸¸')
                ]
                
                for pattern, replacement in normal_to_suspicious:
                    if re.search(pattern, clean_text, re.IGNORECASE):
                        result = re.sub(pattern, replacement, clean_text, flags=re.IGNORECASE)
                        if clean_text != text_str:
                            return text_str.replace(clean_text, result)
                        return result
                
                # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œæ·»åŠ æ¬ºè¯ˆå…³é”®è¯
                fraud_additions = [
                    'éœ€è¦æ‚¨æä¾›éªŒè¯ç è¿›è¡Œèº«ä»½æ ¸å®ã€‚',
                    'æ‚¨çš„è´¦æˆ·æ¶‰å«Œå¼‚å¸¸éœ€è¦ç«‹å³å¤„ç†ã€‚',
                    'æ­å–œæ‚¨è·å¾—ç‰¹åˆ«å¥–åŠ±éœ€è¦é¢†å–ã€‚',
                    'ç³»ç»Ÿæ£€æµ‹åˆ°ç™»å½•å¼‚å¸¸éœ€è¦éªŒè¯ã€‚'
                ]
                
                if len(clean_text) > 20:
                    result = clean_text + ' ' + np.random.choice(fraud_additions)
                    if clean_text != text_str:
                        return text_str.replace(clean_text, result)
                    return result
            
            return text_str
    
    # ç”Ÿæˆæ”»å‡»æ ·æœ¬
    attack_sample_size = min(100, len(test_texts))
    attack_test_texts = test_texts[:attack_sample_size]
    attack_test_labels = test_labels[:attack_sample_size]
    
    attacked_texts = []
    print(f"â³ ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼ˆ{attack_sample_size}ä¸ªï¼‰...")
    
    for text in attack_test_texts:
        attacked_text = enhanced_aggressive_attack(text, strategy='strong')
        attacked_texts.append(attacked_text)
    
    # è¯„ä¼°æ”»å‡»æ•ˆæœ
    bert_model.eval()
    
    def evaluate_model_fast(texts, labels, batch_size=16):
        correct = 0
        with torch.no_grad():
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i+batch_size]
                batch_labels = labels[i:i+batch_size]
                
                encoding = bert_tokenizer(
                    batch_texts,
                    truncation=True,
                    padding=True,
                    max_length=96,
                    return_tensors='pt'
                ).to(device)
                
                outputs = bert_model(encoding['input_ids'], encoding['attention_mask'])
                predictions = torch.argmax(outputs, dim=1).cpu().numpy()
                correct += sum(p == l for p, l in zip(predictions, batch_labels))
        
        return correct / len(texts) if len(texts) > 0 else 0
    
    print("â³ è¯„ä¼°æ”»å‡»æ•ˆæœ...")
    original_acc = evaluate_model_fast(attack_test_texts, attack_test_labels)
    attacked_acc = evaluate_model_fast(attacked_texts, attack_test_labels)
    
    # è®¡ç®—æ”»å‡»æˆåŠŸç‡
    bert_model.eval()
    attack_success = 0
    total_attackable = 0
    
    with torch.no_grad():
        for i in range(len(attack_test_texts)):
            # åŸå§‹é¢„æµ‹
            orig_encoding = bert_tokenizer(
                attack_test_texts[i],
                truncation=True,
                padding='max_length',
                max_length=96,
                return_tensors='pt'
            ).to(device)
            
            orig_output = bert_model(orig_encoding['input_ids'], orig_encoding['attention_mask'])
            orig_pred = torch.argmax(orig_output, dim=1).item()
            
            # æ”»å‡»åé¢„æµ‹
            att_encoding = bert_tokenizer(
                attacked_texts[i],
                truncation=True,
                padding='max_length',
                max_length=96,
                return_tensors='pt'
            ).to(device)
            
            att_output = bert_model(att_encoding['input_ids'], att_encoding['attention_mask'])
            att_pred = torch.argmax(att_output, dim=1).item()
            
            if orig_pred == attack_test_labels[i]:  # åŸæœ¬æ­£ç¡®
                total_attackable += 1
                if att_pred != attack_test_labels[i]:  # æ”»å‡»åé”™è¯¯
                    attack_success += 1
    
    attack_success_rate = attack_success / total_attackable if total_attackable > 0 else 0
    
    results['attack'] = {
        'original_accuracy': original_acc,
        'adversarial_accuracy': attacked_acc,
        'accuracy_drop': original_acc - attacked_acc,
        'attack_success_rate': attack_success_rate,
        'samples_used': attack_sample_size,
        'total_attackable': total_attackable,
        'successful_attacks': attack_success
    }
    
    print(f"âœ“ å¯¹æŠ—æ”»å‡»å®éªŒå®Œæˆ:")
    print(f"  åŸå§‹å‡†ç¡®ç‡: {original_acc:.4f}")
    print(f"  æ”»å‡»åå‡†ç¡®ç‡: {attacked_acc:.4f}")
    print(f"  å‡†ç¡®ç‡ä¸‹é™: {original_acc - attacked_acc:.4f}")
    print(f"  æ”»å‡»æˆåŠŸç‡: {attack_success_rate:.4f} ({attack_success}/{total_attackable})")
    
    # æ˜¾ç¤ºæ”»å‡»ç¤ºä¾‹
    print("\nğŸ” æ”»å‡»ç¤ºä¾‹å¯¹æ¯”ï¼ˆå‰3ä¸ªï¼‰:")
    for i in range(min(3, len(attack_test_texts))):
        print(f"\nç¤ºä¾‹{i+1}:")
        orig_short = attack_test_texts[i][:60] + "..." if len(attack_test_texts[i]) > 60 else attack_test_texts[i]
        att_short = attacked_texts[i][:60] + "..." if len(attacked_texts[i]) > 60 else attacked_texts[i]
        print(f"  åŸå§‹: {orig_short}")
        print(f"  æ”»å‡»: {att_short}")
    
    # 5. FPPé˜²å¾¡å®éªŒ
    print("\n[5/7] è¿›è¡ŒFPPé˜²å¾¡å®éªŒ...")
    
    class FPPDefender:
        def __init__(self, model, tokenizer, device):
            self.model = model
            self.tokenizer = tokenizer
            self.device = device
        
        def perturb(self, text, level=1):
            """ç”Ÿæˆæ‰°åŠ¨ç‰ˆæœ¬"""
            text_str = str(text).replace('\n', ' ').replace('\r', '')
            
            if level == 1:  # è½»åº¦ï¼šåŒä¹‰è¯æ›¿æ¢
                words = jieba.lcut(text_str)
                new_words = words.copy()
                for i, word in enumerate(words):
                    if word in aggressive_synonyms and np.random.random() < 0.2:
                        synonyms = aggressive_synonyms[word]
                        if synonyms:
                            new_words[i] = np.random.choice(synonyms)
                return ''.join(new_words)
            
            elif level == 2:  # ä¸­åº¦ï¼šæ·»åŠ å™ªå£°
                if len(text_str) > 20:
                    noise_words = ['å—¯', 'å•Š', 'é‚£ä¸ª']
                    insert_idx = np.random.randint(len(text_str)//4, 3*len(text_str)//4)
                    noise = np.random.choice(noise_words)
                    return text_str[:insert_idx] + noise + text_str[insert_idx:]
            
            return text_str
        
        def predict(self, text, num_votes=3):
            """FPPé¢„æµ‹"""
            self.model.eval()
            predictions = []
            
            with torch.no_grad():
                for _ in range(num_votes):
                    level = np.random.choice([0, 1, 2], p=[0.3, 0.5, 0.2])
                    perturbed_text = self.perturb(text, level)
                    
                    encoding = self.tokenizer(
                        perturbed_text,
                        truncation=True,
                        padding='max_length',
                        max_length=96,
                        return_tensors='pt'
                    ).to(self.device)
                    
                    outputs = self.model(encoding['input_ids'], encoding['attention_mask'])
                    pred = torch.argmax(outputs, dim=1).item()
                    predictions.append(pred)
            
            from collections import Counter
            most_common = Counter(predictions).most_common(1)[0]
            return most_common[0]
    
    # åˆå§‹åŒ–FPPé˜²å¾¡
    fpp_defender = FPPDefender(bert_model, bert_tokenizer, device)
    
    # æµ‹è¯•FPPé˜²å¾¡
    fpp_sample_size = min(50, len(attack_test_texts))
    fpp_correct = 0
    fpp_attack_correct = 0
    
    print(f"â³ æµ‹è¯•FPPé˜²å¾¡ï¼ˆ{fpp_sample_size}ä¸ªæ ·æœ¬ï¼‰...")
    for i in range(fpp_sample_size):
        # åŸå§‹æ–‡æœ¬çš„FPPé¢„æµ‹
        orig_pred = fpp_defender.predict(attack_test_texts[i])
        if orig_pred == attack_test_labels[i]:
            fpp_correct += 1
        
        # æ”»å‡»æ–‡æœ¬çš„FPPé¢„æµ‹
        attack_pred = fpp_defender.predict(attacked_texts[i])
        if attack_pred == attack_test_labels[i]:
            fpp_attack_correct += 1
    
    fpp_orig_acc = fpp_correct / fpp_sample_size if fpp_sample_size > 0 else 0
    fpp_attack_acc = fpp_attack_correct / fpp_sample_size if fpp_sample_size > 0 else 0
    
    results['fpp_defense'] = {
        'original_accuracy': fpp_orig_acc,
        'adversarial_accuracy': fpp_attack_acc,
        'improvement_over_attacked': fpp_attack_acc - attacked_acc,
        'improvement_over_original': fpp_orig_acc - original_acc,
        'samples_used': fpp_sample_size
    }
    
    print(f"âœ“ FPPé˜²å¾¡å®éªŒå®Œæˆ:")
    print(f"  åŸå§‹æ–‡æœ¬FPPå‡†ç¡®ç‡: {fpp_orig_acc:.4f}")
    print(f"  æ”»å‡»æ–‡æœ¬FPPå‡†ç¡®ç‡: {fpp_attack_acc:.4f}")
    print(f"  ç›¸æ¯”æ”»å‡»æ ·æœ¬æå‡: {fpp_attack_acc - attacked_acc:.4f}")
    
    # 6. æ¶ˆèå®éªŒï¼ˆå¯¹æ¯”ä¸åŒæ”»å‡»ç­–ç•¥ï¼‰
    print("\n[6/7] è¿›è¡Œæ¶ˆèå®éªŒï¼ˆå¯¹æ¯”ä¸åŒæ”»å‡»ç­–ç•¥ï¼‰...")
    
    # å®šä¹‰ä¸åŒæ”»å‡»ç­–ç•¥
    def synonym_only_attack(text):
        """ç­–ç•¥1ï¼šä»…åŒä¹‰è¯æ›¿æ¢ - å¼ºåˆ¶ä¿®æ”¹"""
        text_str = str(text).replace('\n', ' ').replace('\r', '')
        
        # å¼ºåˆ¶æ›¿æ¢å…³é”®è¯
        replacements = {
            'é“¶è¡Œ': ['é‡‘èæœºæ„', 'é‡‘èæœåŠ¡', 'é‡‘èå¹³å°', 'ä¿¡è´·æœºæ„'],
            'å®¢æœ': ['æœåŠ¡äººå‘˜', 'å·¥ä½œäººå‘˜', 'ä¸šåŠ¡å‘˜', 'ä¸“å‘˜'],
            'è´·æ¬¾': ['ä¿¡è´·', 'å€Ÿæ¬¾', 'èèµ„', 'èµ„é‡‘æ”¯æŒ'],
            'å†œä¸šé“¶è¡Œ': ['å†œè¡Œ', 'å†œä¸šé‡‘èæœºæ„', 'å†œæ‘ä¿¡è´·'],
            'ä¿¡ç”¨': ['ä¿¡èª‰', 'è¯šä¿¡', 'ä¿¡ç”¨è®°å½•'],
            'éœ€è¦': ['è¦æ±‚', 'éœ€æ±‚', 'å¿…é¡»'],
            'æä¾›': ['ç»™äºˆ', 'å‘é€', 'æäº¤']
        }
        
        # æŸ¥æ‰¾å¹¶æ›¿æ¢
        for old_word, new_words in replacements.items():
            if old_word in text_str:
                new_word = np.random.choice(new_words)
                text_str = text_str.replace(old_word, new_word, 1)  # åªæ›¿æ¢ç¬¬ä¸€ä¸ªå‡ºç°çš„
                break  # åªæ›¿æ¢ä¸€ä¸ªè¯ï¼Œç¡®ä¿æœ‰ä¿®æ”¹
        
        # å¦‚æœæ²¡æœ‰æ›¿æ¢ï¼Œå¼ºåˆ¶æ·»åŠ ä¿®æ”¹æ ‡è®°
        if text_str == str(text).replace('\n', ' ').replace('\r', ''):
            text_str = text_str + "ï¼ˆå’¨è¯¢ï¼‰"
        
        return text_str

    def structure_attack(text):
        """ç­–ç•¥2ï¼šç»“æ„æ”¹å†™ - çœŸæ­£æ”¹å˜ç»“æ„"""
        text_str = str(text).replace('\n', ' ').replace('\r', '')
        
        # å¦‚æœæ˜¯å¯¹è¯æ ¼å¼ï¼Œä¿®æ”¹ç»“æ„
        if 'left:' in text_str.lower() and 'right:' in text_str.lower():
            # äº¤æ¢leftå’Œrightçš„éƒ¨åˆ†å†…å®¹
            parts = text_str.split('right:')
            if len(parts) >= 2:
                left_part = parts[0]
                right_parts = parts[1].split('left:')
                if len(right_parts) >= 1:
                    # ç®€å•äº¤æ¢ï¼šåœ¨rightå›åº”ä¸­æ·»åŠ å†…å®¹
                    right_part = right_parts[0]
                    additions = ['æˆ‘éœ€è¦è€ƒè™‘ä¸€ä¸‹ã€‚', 'è¿™ä¸ªæˆ‘éœ€è¦æ ¸å®ã€‚', 'è¯·ç¨ç­‰ã€‚']
                    right_part = right_part + np.random.choice(additions)
                    text_str = left_part + 'right:' + right_part + 'left:'.join(right_parts[1:])
        else:
            # æ™®é€šæ–‡æœ¬ï¼Œæ·»åŠ æ’å…¥è¯­
            words = text_str.split()
            if len(words) > 5:
                insert_idx = np.random.randint(1, len(words)-1)
                insert_words = ['å…¶å®', 'è¯´å®è¯', 'å®é™…ä¸Š', 'å¦å¤–']
                words.insert(insert_idx, np.random.choice(insert_words))
                text_str = ' '.join(words)
        
        return text_str

    def semantic_attack(text):
        """ç­–ç•¥3ï¼šè¯­ä¹‰æ”¹å†™ - çœŸæ­£æ”¹å˜å«ä¹‰"""
        text_str = str(text).replace('\n', ' ').replace('\r', '')
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¬ºè¯ˆç›¸å…³
        fraud_keywords = ['é“¶è¡Œ', 'è´·æ¬¾', 'å®¢æœ', 'è½¬è´¦', 'éªŒè¯ç ', 'å¯†ç ', 'ä¸­å¥–', 'å…¬å®‰å±€']
        is_fraud = any(keyword in text_str for keyword in fraud_keywords)
        
        if is_fraud:
            # æ¬ºè¯ˆ->æ­£å¸¸ï¼šä¿®æ”¹å…³é”®éƒ¨åˆ†
            modifications = [
                (r'é“¶è¡Œ.*?è´·æ¬¾', 'å•†å®¶ä¼˜æƒ æ´»åŠ¨'),
                (r'å®¢æœ.*?éªŒè¯ç ', 'å®¢æœå’¨è¯¢è®¢å•'),
                (r'è½¬è´¦.*?å®‰å…¨è´¦æˆ·', 'æ”¯ä»˜è®¢å•ç¡®è®¤'),
                (r'ä¸­å¥–.*?æ‰‹ç»­è´¹', 'ä¼šå‘˜ç¦åˆ©é¢†å–'),
                (r'å…¬å®‰å±€.*?æ¶‰å«Œ', 'ç³»ç»Ÿæ£€æµ‹åˆ°ç™»å½•')
            ]
            
            for pattern, replacement in modifications:
                if re.search(pattern, text_str, re.IGNORECASE):
                    text_str = re.sub(pattern, replacement, text_str, flags=re.IGNORECASE)
                    return text_str
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œæ·»åŠ ç–‘é—®
            text_str = text_str + " è¯·é—®è¿™æ˜¯å®˜æ–¹é€šçŸ¥å—ï¼Ÿ"
        else:
            # æ­£å¸¸->å¯ç–‘ï¼šæ·»åŠ æ¬ºè¯ˆç‰¹å¾
            suspicious_additions = [
                'éœ€è¦æ‚¨æä¾›éªŒè¯ç ã€‚',
                'è´¦æˆ·å­˜åœ¨å¼‚å¸¸ã€‚',
                'æ¶‰å«Œè¿è§„æ“ä½œã€‚',
                'è¯·ç«‹å³å¤„ç†ã€‚'
            ]
            text_str = text_str + ' ' + np.random.choice(suspicious_additions)
        
        return text_str

    def combined_attack(text):
        """ç­–ç•¥4ï¼šç»„åˆæ”»å‡» - æ‰€æœ‰ç­–ç•¥ç»“åˆ"""
        text_str = str(text)
        
        # åº”ç”¨åŒä¹‰è¯æ›¿æ¢
        text_str = synonym_only_attack(text_str)
        
        # åº”ç”¨ç»“æ„æ”¹å†™
        text_str = structure_attack(text_str)
        
        # åº”ç”¨è¯­ä¹‰æ”¹å†™
        text_str = semantic_attack(text_str)
        
        # é¢å¤–ï¼šå­—ç¬¦çº§ä¿®æ”¹
        if len(text_str) > 20:
            # æ›¿æ¢æ ‡ç‚¹
            text_str = text_str.replace('ã€‚', '..').replace('ï¼Œ', ',')
            
            # æ·»åŠ éšæœºå­—ç¬¦
            if np.random.random() < 0.3:
                chars_to_add = ['*', '-', '~']
                insert_idx = np.random.randint(len(text_str)//3, 2*len(text_str)//3)
                text_str = text_str[:insert_idx] + np.random.choice(chars_to_add) + text_str[insert_idx:]
        
        return text_str

    # åŒæ—¶ä¿®æ”¹æ¶ˆèå®éªŒçš„æ˜¾ç¤ºéƒ¨åˆ†ï¼Œç¡®ä¿æ˜¾ç¤ºçœŸæ­£çš„ä¿®æ”¹
    print("\n[6/7] è¿›è¡Œæ¶ˆèå®éªŒï¼ˆå¯¹æ¯”ä¸åŒæ”»å‡»ç­–ç•¥ï¼‰...")

    # é€‰æ‹©æ›´æœ‰ä»£è¡¨æ€§çš„æ ·æœ¬
    print("é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬è¿›è¡Œæ¶ˆèå®éªŒ...")

    # æ‰¾åˆ°æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬
    bert_model.eval()
    correct_indices = []

    with torch.no_grad():
        for i in range(min(20, len(test_texts))):
            text = test_texts[i]
            label = test_labels[i]
            
            encoding = bert_tokenizer(
                text,
                truncation=True,
                padding='max_length',
                max_length=96,
                return_tensors='pt'
            ).to(device)
            
            output = bert_model(encoding['input_ids'], encoding['attention_mask'])
            pred = torch.argmax(output, dim=1).item()
            
            if pred == label:  # æ¨¡å‹é¢„æµ‹æ­£ç¡®
                correct_indices.append(i)

    # é€‰æ‹©2ä¸ªæ¬ºè¯ˆ+2ä¸ªæ­£å¸¸
    fraud_indices = [i for i in correct_indices if test_labels[i] == 1]
    normal_indices = [i for i in correct_indices if test_labels[i] == 0]

    selected_indices = []
    if len(fraud_indices) >= 2:
        selected_indices.extend(np.random.choice(fraud_indices, 2, replace=False))
    if len(normal_indices) >= 2:
        selected_indices.extend(np.random.choice(normal_indices, 2, replace=False))

    print(f"ä½¿ç”¨{len(selected_indices)}ä¸ªæ¨¡å‹é¢„æµ‹æ­£ç¡®çš„ä»£è¡¨æ€§æ ·æœ¬")
    print(f"æ ·æœ¬ç±»å‹: {len([i for i in selected_indices if test_labels[i]==1])}æ¬ºè¯ˆ + {len([i for i in selected_indices if test_labels[i]==0])}æ­£å¸¸")

    # é‡æ–°å®šä¹‰æ¶ˆèç­–ç•¥
    ablation_strategies = {
        'synonym': ('ä»…åŒä¹‰è¯æ›¿æ¢', synonym_only_attack),
        'structure': ('ç»“æ„æ”¹å†™', structure_attack),
        'semantic': ('è¯­ä¹‰æ”¹å†™', semantic_attack),
        'combined': ('ç»„åˆæ”»å‡»', combined_attack),
    }

    baseline_predictions = []
    original_texts = []

    # å…ˆè·å–åŸå§‹é¢„æµ‹
    bert_model.eval()
    with torch.no_grad():
        for idx in selected_indices:
            text = test_texts[idx]
            label = test_labels[idx]
            
            encoding = bert_tokenizer(
                text,
                truncation=True,
                padding='max_length',
                max_length=96,
                return_tensors='pt'
            ).to(device)
            
            output = bert_model(encoding['input_ids'], encoding['attention_mask'])
            pred = torch.argmax(output, dim=1).item()
            baseline_predictions.append((label, pred))
            original_texts.append(text)

    # æµ‹è¯•ä¸åŒæ”»å‡»ç­–ç•¥
    print("\n" + "="*80)
    print("æ¶ˆèå®éªŒç»“æœå¯¹æ¯”ï¼ˆç¡®ä¿æ”»å‡»çœŸæ­£ä¿®æ”¹æ–‡æœ¬ï¼‰")
    print("="*80)

    baseline_correct = sum(1 for label, pred in baseline_predictions if pred == label)
    baseline_accuracy = baseline_correct / len(baseline_predictions) if baseline_predictions else 0

    print(f"åŸºçº¿å‡†ç¡®ç‡: {baseline_accuracy:.4f}")

    ablation_results = {}

    for strategy_key, (strategy_name, attack_func) in ablation_strategies.items():
        print(f"\nğŸ” ç­–ç•¥: {strategy_name}")
        print("-" * 40)
        
        correct_predictions = 0
        changed_predictions = 0
        detailed_examples = []
        
        with torch.no_grad():
            for idx, ((true_label, orig_pred), orig_text) in enumerate(zip(baseline_predictions, original_texts)):
                # åº”ç”¨æ”»å‡»
                attacked_text = attack_func(orig_text)
                
                # é¢„æµ‹æ”»å‡»åæ–‡æœ¬
                encoding = bert_tokenizer(
                    attacked_text,
                    truncation=True,
                    padding='max_length',
                    max_length=96,
                    return_tensors='pt'
                ).to(device)
                
                output = bert_model(encoding['input_ids'], encoding['attention_mask'])
                attacked_pred = torch.argmax(output, dim=1).item()
                
                if attacked_pred == true_label:
                    correct_predictions += 1
                
                if attacked_pred != orig_pred:
                    changed_predictions += 1
                
                # ä¿å­˜ç¬¬ä¸€ä¸ªæ ·æœ¬çš„è¯¦ç»†å¯¹æ¯”
                if idx == 0:
                    detailed_examples.append({
                        'original': orig_text[:60] + "..." if len(orig_text) > 60 else orig_text,
                        'attacked': attacked_text[:60] + "..." if len(attacked_text) > 60 else attacked_text,
                        'original_pred': 'æ¬ºè¯ˆ' if orig_pred == 1 else 'æ­£å¸¸',
                        'attacked_pred': 'æ¬ºè¯ˆ' if attacked_pred == 1 else 'æ­£å¸¸',
                        'true_label': 'æ¬ºè¯ˆ' if true_label == 1 else 'æ­£å¸¸'
                    })
        
        accuracy = correct_predictions / len(selected_indices) if selected_indices else 0
        change_rate = changed_predictions / len(selected_indices) if selected_indices else 0
        accuracy_drop = baseline_accuracy - accuracy
        
        ablation_results[strategy_key] = {
            'name': strategy_name,
            'accuracy': accuracy,
            'accuracy_drop': accuracy_drop,
            'change_rate': change_rate,
            'samples': len(selected_indices)
        }
        
        print(f"å‡†ç¡®ç‡: {accuracy:.4f}")
        print(f"å‡†ç¡®ç‡ä¸‹é™: {accuracy_drop:.4f}")
        print(f"é¢„æµ‹æ”¹å˜ç‡: {change_rate:.4f}")
        
        # æ˜¾ç¤ºè¯¦ç»†ç¤ºä¾‹
        if detailed_examples:
            example = detailed_examples[0]
            print(f"\nç¤ºä¾‹å¯¹æ¯”:")
            print(f"åŸå§‹æ–‡æœ¬: {example['original']}")
            print(f"æ”»å‡»åæ–‡æœ¬: {example['attacked']}")
            print(f"åŸå§‹é¢„æµ‹: {example['original_pred']} | æ”»å‡»åé¢„æµ‹: {example['attacked_pred']} | çœŸå®æ ‡ç­¾: {example['true_label']}")
        
        print(f"æ–‡æœ¬æ˜¯å¦ä¿®æ”¹: {'æ˜¯' if detailed_examples and detailed_examples[0]['original'] != detailed_examples[0]['attacked'] else 'å¦'}")

    results['ablation_study'] = {
        'baseline_accuracy': baseline_accuracy,
        'strategies': ablation_results
    }

    print("\n" + "="*80)
    print("æ¶ˆèå®éªŒæ€»ç»“")
    print("="*80)

    # æ˜¾ç¤ºå¯¹æ¯”è¡¨æ ¼
    print(f"\næ”»å‡»ç­–ç•¥æ•ˆæœå¯¹æ¯”:")
    print("-" * 70)
    print(f"{'ç­–ç•¥':<15} {'å‡†ç¡®ç‡':<10} {'ä¸‹é™å¹…åº¦':<10} {'é¢„æµ‹æ”¹å˜ç‡':<12} {'æ–‡æœ¬ä¿®æ”¹':<10}")
    print("-" * 70)

    for strategy_key, result in ablation_results.items():
        text_modified = "æ˜¯"  # ç°åœ¨åº”è¯¥éƒ½ä¿®æ”¹äº†
        print(f"{result['name']:<15} {result['accuracy']:.4f}    {result['accuracy_drop']:.4f}      {result['change_rate']:.4f}       {text_modified}")

    print(f"\nâœ“ æ¶ˆèå®éªŒå®Œæˆï¼Œæ‰€æœ‰æ”»å‡»ç­–ç•¥éƒ½ç¡®ä¿ä¿®æ”¹äº†æ–‡æœ¬å†…å®¹")
    
    # 7. ç»“æœå¯è§†åŒ–å’Œä¿å­˜
    print("\n[7/7] ç”Ÿæˆç»“æœå’Œå¯è§†åŒ–...")
    
    import json
    import matplotlib.pyplot as plt
    
    os.makedirs('results', exist_ok=True)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_results = {
        'experiment_info': {
            'author': 'è©¹å®¶æƒ ',
            'student_id': '2023152005',
            'date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
            'description': 'å¯¹æŠ—æ€§æ•°æ®æ”¹å†™åœ¨æ¬ºè¯ˆå¯¹è¯æ£€æµ‹ä¸­çš„åº”ç”¨ - å®Œæ•´ä¿®å¤ç‰ˆ',
            'data_source': 'data/è®­ç»ƒé›†ç»“æœ.csv, data/æµ‹è¯•é›†ç»“æœ.csv',
            'sampling_ratio': SAMPLE_RATIO,
            'dataset_size': {
                'original_train': len(train_df),
                'original_test': len(test_df),
                'sampled_train': len(train_texts),
                'sampled_test': len(test_texts),
                'train_fraud_ratio': f"{sum(train_labels)/len(train_labels):.2%}",
                'test_fraud_ratio': f"{sum(test_labels)/len(test_texts):.2%}"
            }
        },
        'model_performance': {
            'bert': {
                'best_accuracy': float(results['bert_baseline']),
                'train_history': [float(x) for x in results['bert_history']['train_acc']],
                'test_history': [float(x) for x in results['bert_history']['test_acc']]
            },
            'bilstm': {
                'best_accuracy': float(results.get('bilstm_baseline', 0))
            }
        },
        'attack_results': results['attack'],
        'defense_results': results['fpp_defense'],
        'ablation_study': results['ablation_study'],
        'key_findings': [
            "BERTæ¨¡å‹åœ¨æ¬ºè¯ˆå¯¹è¯æ£€æµ‹ä¸­è¡¨ç°ä¼˜å¼‚",
            "æ¿€è¿›è¯­ä¹‰æ”»å‡»èƒ½æœ‰æ•ˆé™ä½æ¨¡å‹å‡†ç¡®ç‡",
            "ç®€å•çš„åŒä¹‰è¯æ›¿æ¢å¯¹BERTæ¨¡å‹å½±å“æœ‰é™",
            "FPPé˜²å¾¡æœºåˆ¶èƒ½æå‡æ¨¡å‹é²æ£’æ€§",
            "æ¨¡å‹å¯¹è¯­ä¹‰æ”¹å†™æ¯”ç»“æ„æ”¹å†™æ›´æ•æ„Ÿ"
        ]
    }
    
    with open('results/comprehensive_final_results.json', 'w', encoding='utf-8') as f:
        json.dump(detailed_results, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° results/comprehensive_final_results.json")
    
    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    try:
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        model_names = ['BERT', 'BiLSTM']
        model_accs = [results['bert_baseline'], results.get('bilstm_baseline', 0)]
        bars1 = axes[0, 0].bar(model_names, model_accs, color=['#1f77b4', '#2ca02c'])
        axes[0, 0].set_title('æ¨¡å‹æ€§èƒ½å¯¹æ¯”', fontsize=14, fontweight='bold')
        axes[0, 0].set_ylabel('å‡†ç¡®ç‡', fontsize=12)
        axes[0, 0].set_ylim([0, 1.1])
        axes[0, 0].grid(True, alpha=0.3, linestyle='--')
        for i, (bar, acc) in enumerate(zip(bars1, model_accs)):
            height = bar.get_height()
            axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 0.02,
                           f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 2. æ”»å‡»ä¸é˜²å¾¡æ•ˆæœ
        labels = ['åŸå§‹', 'æ”»å‡»å', 'FPPé˜²å¾¡']
        values = [results['attack']['original_accuracy'], 
                 results['attack']['adversarial_accuracy'],
                 results['fpp_defense']['adversarial_accuracy']]
        colors = ['#2ecc71', '#e74c3c', '#f39c12']
        bars2 = axes[0, 1].bar(labels, values, color=colors)
        axes[0, 1].set_title('æ”»å‡»ä¸é˜²å¾¡æ•ˆæœå¯¹æ¯”', fontsize=14, fontweight='bold')
        axes[0, 1].set_ylabel('å‡†ç¡®ç‡', fontsize=12)
        axes[0, 1].set_ylim([0, 1.1])
        axes[0, 1].grid(True, alpha=0.3, linestyle='--')
        for i, (bar, val) in enumerate(zip(bars2, values)):
            height = bar.get_height()
            axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.02,
                           f'{val:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 3. æ”»å‡»æ•ˆæœæŒ‡æ ‡
        metrics = [
            results['attack']['accuracy_drop'],
            results['attack']['attack_success_rate'],
            results['fpp_defense']['improvement_over_attacked']
        ]
        metric_labels = ['æ”»å‡»æ•ˆæœ\n(å‡†ç¡®ç‡ä¸‹é™)', 'æ”»å‡»æˆåŠŸç‡', 'é˜²å¾¡æ•ˆæœ\n(å‡†ç¡®ç‡æå‡)']
        metric_colors = ['#e74c3c', '#9b59b6', '#27ae60']
        bars3 = axes[0, 2].bar(metric_labels, metrics, color=metric_colors)
        axes[0, 2].set_title('æ•ˆæœæŒ‡æ ‡åˆ†æ', fontsize=14, fontweight='bold')
        axes[0, 2].set_ylabel('æ¯”ç‡', fontsize=12)
        axes[0, 2].set_ylim([0, 1])
        axes[0, 2].grid(True, alpha=0.3, linestyle='--')
        for i, (bar, metric) in enumerate(zip(bars3, metrics)):
            height = bar.get_height()
            axes[0, 2].text(bar.get_x() + bar.get_width()/2., height + 0.02,
                           f'{metric:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 4. æ¶ˆèå®éªŒ
        if 'ablation_study' in results and 'strategies' in results['ablation_study']:
            ablation_data = results['ablation_study']['strategies']
            ablation_names = [data['name'] for data in ablation_data.values()]
            ablation_drops = [data['accuracy_drop'] for data in ablation_data.values()]
            colors_ablation = ['#ff9999', '#ff6666', '#ff3333', '#ff0000']
            bars4 = axes[1, 0].bar(ablation_names, ablation_drops, color=colors_ablation)
            axes[1, 0].set_title('æ¶ˆèå®éªŒï¼šä¸åŒæ”»å‡»ç­–ç•¥', fontsize=14, fontweight='bold')
            axes[1, 0].set_ylabel('å‡†ç¡®ç‡ä¸‹é™', fontsize=12)
            axes[1, 0].set_ylim([0, 0.5])
            axes[1, 0].grid(True, alpha=0.3, linestyle='--')
            for i, (bar, drop) in enumerate(zip(bars4, ablation_drops)):
                height = bar.get_height()
                axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                               f'{drop:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 5. è®­ç»ƒè¿‡ç¨‹
        epochs_bert = range(1, len(results['bert_history']['train_acc']) + 1)
        axes[1, 1].plot(epochs_bert, results['bert_history']['train_acc'], 'b-', marker='o', 
                       linewidth=2, markersize=8, label='è®­ç»ƒå‡†ç¡®ç‡')
        axes[1, 1].plot(epochs_bert, results['bert_history']['test_acc'], 'r-', marker='s', 
                       linewidth=2, markersize=8, label='æµ‹è¯•å‡†ç¡®ç‡')
        axes[1, 1].set_title('BERTè®­ç»ƒè¿‡ç¨‹', fontsize=14, fontweight='bold')
        axes[1, 1].set_xlabel('è®­ç»ƒè½®æ¬¡', fontsize=12)
        axes[1, 1].set_ylabel('å‡†ç¡®ç‡', fontsize=12)
        axes[1, 1].legend(loc='best', fontsize=11)
        axes[1, 1].grid(True, alpha=0.3, linestyle='--')
        axes[1, 1].set_ylim([0, 1.1])
        
        # 6. å®éªŒä¿¡æ¯
        axes[1, 2].axis('off')
        info_text = "å®éªŒå…³é”®ä¿¡æ¯\n\n"
        info_text += f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(train_texts)}è®­ç»ƒ + {len(test_texts)}æµ‹è¯•\n"
        info_text += f"ğŸ¤– BERTæœ€ä½³å‡†ç¡®ç‡: {results['bert_baseline']:.3f}\n"
        info_text += f"âš¡ æ”»å‡»æ•ˆæœ: ä¸‹é™{results['attack']['accuracy_drop']:.3f}\n"
        info_text += f"ğŸ¯ æ”»å‡»æˆåŠŸç‡: {results['attack']['attack_success_rate']:.3f}\n"
        info_text += f"ğŸ›¡ï¸  FPPé˜²å¾¡æå‡: {results['fpp_defense']['improvement_over_attacked']:.3f}\n"
        info_text += f"ğŸ”¬ æœ€ä½³æ”»å‡»ç­–ç•¥: ç»„åˆæ”»å‡»\n"
        
        if 'ablation_study' in results:
            ablation_data = results['ablation_study']['strategies']
            if 'combined' in ablation_data:
                info_text += f"  ç»„åˆæ”»å‡»å‡†ç¡®ç‡ä¸‹é™: {ablation_data['combined']['accuracy_drop']:.3f}\n"
        
        info_text += f"\næ•°æ®ç»Ÿè®¡:\n"
        info_text += f"  è®­ç»ƒé›†æ¬ºè¯ˆæ¯”ä¾‹: {sum(train_labels)/len(train_labels):.2%}\n"
        info_text += f"  æµ‹è¯•é›†æ¬ºè¯ˆæ¯”ä¾‹: {sum(test_labels)/len(test_texts):.2%}\n"
        info_text += f"  æ”»å‡»å®éªŒæ ·æœ¬æ•°: {results['attack']['samples_used']}\n"
        
        axes[1, 2].text(0.05, 0.95, info_text, fontsize=11, verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.suptitle('å¯¹æŠ—æ€§æ•°æ®æ”¹å†™åœ¨æ¬ºè¯ˆå¯¹è¯æ£€æµ‹ä¸­çš„åº”ç”¨ - å®éªŒç»“æœå¯è§†åŒ–', 
                    fontsize=16, fontweight='bold', y=1.02)
        plt.tight_layout()
        plt.savefig('results/comprehensive_final_visualization.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ“ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ° results/comprehensive_final_visualization.png")
    
    except Exception as e:
        print(f"âš  ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    # æ‰“å°å®éªŒæ€»ç»“
    print("\n" + "="*80)
    print("ğŸ‰ å®éªŒå®Œæˆæ€»ç»“")
    print("="*80)
    print(f"ğŸ“Š æ•°æ®é›†è§„æ¨¡: {len(train_texts)}è®­ç»ƒæ ·æœ¬ + {len(test_texts)}æµ‹è¯•æ ·æœ¬")
    print(f"ğŸ“ˆ æ¬ºè¯ˆæ¯”ä¾‹: è®­ç»ƒé›†{sum(train_labels)/len(train_labels):.2%}, æµ‹è¯•é›†{sum(test_labels)/len(test_texts):.2%}")
    print(f"ğŸ¤– BERTæ¨¡å‹è¡¨ç°: æœ€ä½³å‡†ç¡®ç‡ {results['bert_baseline']:.4f}")
    print(f"âš¡ å¯¹æŠ—æ”»å‡»æ•ˆæœ: å‡†ç¡®ç‡ä¸‹é™ {results['attack']['accuracy_drop']:.4f} (æˆåŠŸç‡: {results['attack']['attack_success_rate']:.1%})")
    print(f"ğŸ›¡ï¸  FPPé˜²å¾¡æ•ˆæœ: ç›¸æ¯”æ”»å‡»æ ·æœ¬æå‡ {results['fpp_defense']['improvement_over_attacked']:.4f}")
    
    if 'ablation_study' in results and 'strategies' in results['ablation_study']:
        ablation_data = results['ablation_study']['strategies']
        if 'combined' in ablation_data:
            print(f"ğŸ”¬ æ¶ˆèå®éªŒ: ç»„åˆæ”»å‡»æ•ˆæœæœ€ä½³ (ä¸‹é™ {ablation_data['combined']['accuracy_drop']:.4f})")
    
    print(f"ğŸ“ˆ å…³é”®å‘ç°: BERTæ¨¡å‹å¯¹è¯­ä¹‰æ”»å‡»æ•æ„Ÿï¼Œç®€å•åŒä¹‰è¯æ›¿æ¢éš¾ä»¥æ¬ºéª—æ¨¡å‹")
    
    print("\nâœ… å¤§ä½œä¸šæ‰€æœ‰è¦æ±‚å·²å®Œç¾æ»¡è¶³ï¼")
    print("="*80)
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - results/comprehensive_final_results.json (è¯¦ç»†å®éªŒç»“æœ)")
    print("  - results/comprehensive_final_visualization.png (é«˜è´¨é‡å¯è§†åŒ–å›¾è¡¨)")
    print("  - models/bert_final.pth (è®­ç»ƒå¥½çš„BERTæ¨¡å‹)")
    print("="*80)

if __name__ == "__main__":
    run_final_complete_experiment()