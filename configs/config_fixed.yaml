experiment:
  batch_size: 16
  device: cuda
  num_epochs: 5
  random_seed: 42
fpp:
  kappa: 0.2
  lambda_param: 0.5
  num_samples: 10
  voting_type: majority
models:
  bert:
    dropout: 0.3
    learning_rate: 2.0e-05
    max_length: 512
    model_name: bert-base-chinese
  bilstm:
    dropout: 0.5
    embedding_dim: 300
    hidden_dim: 256
    learning_rate: 0.001
    max_length: 200
    num_layers: 2
paths:
  adversarial_dir: adversarial_samples
  data_dir: data
  model_dir: models
  result_dir: results
