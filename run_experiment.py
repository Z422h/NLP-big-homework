# run_strong_attack_experiment.py
"""
å¼ºåŠ›æ”»å‡»FPPå®žéªŒï¼šä½¿ç”¨æ›´æ¿€è¿›çš„æ”»å‡»ç­–ç•¥
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
from sklearn.model_selection import train_test_split
import re
import warnings
import random
import os
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from tqdm import tqdm
import jieba

warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

print("="*80)
print("å¼ºåŠ›æ”»å‡»FPPå®žéªŒ")
print("="*80)

# ========== 1. å¼ºåŠ›æ”»å‡»å™¨ ==========
class StrongFraudAttacker:
    """å¼ºåŠ›æ¬ºè¯ˆæ–‡æœ¬æ”»å‡»å™¨"""
    
    def __init__(self):
        # æ‰©å±•çš„æ¬ºè¯ˆå…³é”®è¯è¯å…¸
        self.fraud_keywords = {
            'è½¬è´¦': ['åˆ’è½¬', 'è½¬æ¬¾', 'æ±‡æ¬¾', 'èµ„é‡‘è½¬ç§»', 'æ‰“æ¬¾', 'è½¬å‡º', 'æ”¯ä»˜'],
            'éªŒè¯ç ': ['ç¡®è®¤ç ', 'æ ¡éªŒç ', 'å®‰å…¨ç ', 'åŠ¨æ€ç ', 'éªŒè¯æ•°å­—', 'éªŒè¯å¯†ç '],
            'å…¬å®‰å±€': ['è­¦æ–¹', 'å…¬å®‰æœºå…³', 'è­¦å¯Ÿå±€', 'å…¬å®‰éƒ¨é—¨', 'è­¦å±€', 'æ´¾å‡ºæ‰€'],
            'å®‰å…¨è´¦æˆ·': ['ç›‘ç®¡è´¦æˆ·', 'å®‰å…¨æˆ·å¤´', 'ä¿æŠ¤è´¦æˆ·', 'ä¿é™©è´¦æˆ·', 'ä¸“ç”¨è´¦æˆ·'],
            'å¯†ç ': ['å£ä»¤', 'å¯†é’¥', 'ç™»å½•å¯†ç ', 'è´¦æˆ·å¯†ç ', 'ç”¨æˆ·å¯†ç '],
            'å†»ç»“': ['é”å®š', 'å°å­˜', 'æ­¢ä»˜', 'è´¦æˆ·å†»ç»“', 'èµ„é‡‘å†»ç»“'],
            'å¼‚å¸¸': ['ä¸æ­£å¸¸', 'æœ‰é—®é¢˜', 'å¼‚å¸¸æƒ…å†µ', 'å¼‚æ ·', 'é—®é¢˜çŠ¶æ€'],
            'å®¢æœ': ['å®¢æˆ·æœåŠ¡', 'æœåŠ¡ä¸“å‘˜', 'åœ¨çº¿å®¢æœ', 'äººå·¥å®¢æœ', 'å®¢æœäººå‘˜'],
            'é“¶è¡Œ': ['é‡‘èžæœºæž„', 'å‚¨è“„æ‰€', 'é“¶è¡Œæœºæž„', 'å•†ä¸šé“¶è¡Œ', 'å‚¨è“„é“¶è¡Œ'],
            'ç³»ç»Ÿ': ['å¹³å°', 'ç³»ç»Ÿå¹³å°', 'æ“ä½œç³»ç»Ÿ', 'è½¯ä»¶ç³»ç»Ÿ'],
            'æ£€æµ‹': ['æ£€æŸ¥', 'ç›‘æŽ§', 'æ£€æµ‹æ£€æŸ¥', 'ç³»ç»Ÿæ£€æµ‹'],
            'é€šçŸ¥': ['å‘ŠçŸ¥', 'æé†’', 'é€šå‘Š', 'é€šçŸ¥æé†’'],
            'æ“ä½œ': ['å¤„ç†', 'æ‰§è¡Œ', 'è¿›è¡Œ', 'æ“ä½œå¤„ç†'],
            'ç¡®è®¤': ['æ ¸å®ž', 'ç¡®å®š', 'æŸ¥è¯', 'ç¡®è®¤æ ¸å®ž'],
            'æä¾›': ['æäº¤', 'ç»™å‡º', 'ä¸Šä¼ ', 'æä¾›æäº¤'],
            'å®Œæˆ': ['ç»“æŸ', 'æžå®š', 'å®Œæˆæ“ä½œ', 'æ“ä½œå®Œæˆ'],
            'ç™»å½•': ['ç™»å…¥', 'è¿›å…¥', 'è®¿é—®', 'ç™»å½•ç³»ç»Ÿ'],
            'é‡è¦': ['å…³é”®', 'ç´§è¦', 'é‡è¦å…³é”®', 'éžå¸¸é‡è¦'],
            'ç´§æ€¥': ['è¿«åˆ‡', 'ç´§æ€¥æƒ…å†µ', 'ç´§è¦', 'æ€¥è¿«'],
            'é£Žé™©': ['å±é™©', 'éšæ‚£', 'é£Žé™©éšæ‚£', 'å®‰å…¨é£Žé™©'],
        }
        
        # å¼ºåŠ›æ··æ·†å†…å®¹
        self.strong_confusions = [
            "ã€å…¬å®‰å±€ç½‘ç»œå®‰å…¨ä¸­å¿ƒã€‘ç´§æ€¥é€šæŠ¥ï¼šè¯·ç«‹å³å¤„ç†ï¼",
            "ã€é“¶è¡Œåè¯ˆä¸­å¿ƒã€‘é‡è¦è­¦å‘Šï¼šä¸åŠæ—¶å¤„ç†å°†æ°¸ä¹…å†»ç»“è´¦æˆ·ï¼",
            "ã€å›½å®¶åè¯ˆä¸­å¿ƒã€‘æ£€æµ‹åˆ°æ‚¨çš„è´¦æˆ·å­˜åœ¨é‡å¤§é£Žé™©ï¼",
            "å›žå¤TDé€€è®¢æœ¬é€šçŸ¥ï¼Œè¯¦è¯¢å®¢æœç”µè¯400-000-0000",
            "ç‚¹å‡»é“¾æŽ¥http://fake-bank.com/verify å®Œæˆå®‰å…¨éªŒè¯",
            "æ ¹æ®ã€Šç½‘ç»œå®‰å…¨æ³•ã€‹ç›¸å…³è§„å®šï¼Œè¯·åŠæ—¶å®Œæˆè®¤è¯",
            "å…¬å®‰æœºå…³å·²ä»‹å…¥è°ƒæŸ¥ï¼Œè¯·é…åˆæä¾›ç›¸å…³ä¿¡æ¯",
            "é“¶ç›‘ä¼šè¦æ±‚ç«‹å³å¤„ç†ï¼Œå¦åˆ™å°†æ‰¿æ‹…æ³•å¾‹è´£ä»»",
            "æ¶‰å«Œè¿ååˆ‘æ³•ç¬¬266æ¡è¯ˆéª—ç½ªï¼Œè¯·ç«‹å³æ ¸å®ž",
            "æ­¤æ“ä½œå…·æœ‰æ³•å¾‹æ•ˆåŠ›ï¼Œè¯·è°¨æ…Žå¤„ç†",
        ]
        
        # æ¬ºè¯ˆæ¨¡å¼æ¨¡æ¿
        self.fraud_templates = [
            "{}ï¼Œè¯·ç«‹å³è½¬è´¦åˆ°å®‰å…¨è´¦æˆ·è¿›è¡ŒéªŒè¯",
            "{}ï¼Œå…¬å®‰å±€è¦æ±‚é…åˆè°ƒæŸ¥æä¾›éªŒè¯ç ",
            "{}ï¼Œç³»ç»Ÿæ£€æµ‹å¼‚å¸¸éœ€è¦ç«‹å³ä¿®æ”¹å¯†ç ",
            "{}ï¼Œå®¢æœæç¤ºè´¦æˆ·å°†è¢«å†»ç»“è¯·å°½å¿«æ¿€æ´»",
            "{}ï¼Œé“¶è¡Œé€šçŸ¥æ¶‰åŠè¯ˆéª—æ¡ˆä»¶è¯·é…åˆå¤„ç†",
            "{}ï¼Œå®‰å…¨ä¸­å¿ƒæ£€æµ‹åˆ°é£Žé™©è¯·æ ¸å®žèº«ä»½",
            "{}ï¼Œè´¦æˆ·å­˜åœ¨å¼‚å¸¸æ“ä½œè¯·ç«‹å³åœæ­¢",
            "{}ï¼Œç³»ç»Ÿè­¦æŠ¥èµ„é‡‘å¼‚å¸¸æµåŠ¨è¯·ç¡®è®¤",
            "{}ï¼Œå…¬å®‰æœºå…³è¦æ±‚é…åˆæä¾›è´¦æˆ·ä¿¡æ¯",
            "{}ï¼ŒéªŒè¯ç å·²å‘é€è¯·è¾“å…¥å®ŒæˆéªŒè¯",
        ]
        
        # åŒéŸ³å­—æ›¿æ¢
        self.homophone_map = {
            'è½¬': ['ä¸“', 'ä¼ ', 'ç –'],
            'è´¦': ['å¸', 'ä¸ˆ', 'ä»—'],
            'ç ': ['é©¬', 'å¦ˆ', 'éº»'],
            'é“¶': ['èµ¢', 'æ·«', 'åŸ'],
            'è¡Œ': ['å½¢', 'åž‹', 'åˆ‘'],
            'å…¬': ['å·¥', 'åŠŸ', 'æ”»'],
            'å®‰': ['æŒ‰', 'å²¸', 'æ¡ˆ'],
            'å…¨': ['æƒ', 'æ³‰', 'æ‹³'],
            'è¯': ['æ­£', 'æ”¿', 'ç—‡'],
            'éªŒ': ['çœ¼', 'æ¼”', 'ç‡•'],
        }
        
        # åœç”¨è¯ï¼ˆç”¨äºŽåˆ é™¤æ”»å‡»ï¼‰
        self.stopwords = ['çš„', 'äº†', 'åœ¨', 'å’Œ', 'æ˜¯', 'æœ‰', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'è¿™', 'é‚£', 'å°±', 'ä¹Ÿ', 'è¿˜']
    
    def extract_key_sentences(self, text, n_sentences=3):
        """æå–å…³é”®å¥å­ï¼ˆåŒ…å«æ¬ºè¯ˆå…³é”®è¯çš„å¥å­ï¼‰"""
        # ç®€å•æŒ‰æ ‡ç‚¹åˆ†å‰²å¥å­
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼›]', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # æ‰¾åˆ°åŒ…å«æ¬ºè¯ˆå…³é”®è¯çš„å¥å­
        key_sentences = []
        for sentence in sentences:
            for keyword in self.fraud_keywords:
                if keyword in sentence and len(sentence) > 10:
                    key_sentences.append(sentence)
                    break
        
        # å¦‚æžœæ²¡æœ‰æ‰¾åˆ°å…³é”®å¥å­ï¼Œè¿”å›žå‰å‡ ä¸ªå¥å­
        if not key_sentences and sentences:
            return sentences[:min(n_sentences, len(sentences))]
        
        return key_sentences[:min(n_sentences, len(key_sentences))]
    
    def strong_synonym_attack(self, text, is_fraud=True):
        """å¼ºåŠ›åŒä¹‰è¯æ›¿æ¢æ”»å‡»"""
        if not is_fraud:
            return text
        
        result = text
        
        # 1. åŒä¹‰è¯æ›¿æ¢
        for keyword, synonyms in self.fraud_keywords.items():
            if keyword in result and synonyms:
                # æ›¿æ¢æ‰€æœ‰å‡ºçŽ°çš„å…³é”®è¯
                for _ in range(result.count(keyword)):
                    if random.random() > 0.7:  # 70%æ¦‚çŽ‡æ›¿æ¢
                        synonym = random.choice(synonyms)
                        result = result.replace(keyword, synonym, 1)
        
        # 2. åŒéŸ³å­—æ›¿æ¢
        for char, replacements in self.homophone_map.items():
            if char in result:
                result = result.replace(char, random.choice(replacements))
        
        return result
    
    def sentence_replacement_attack(self, text, is_fraud=True):
        """å¥å­æ›¿æ¢æ”»å‡»"""
        if not is_fraud:
            return text
        
        # æå–å…³é”®å¥å­
        key_sentences = self.extract_key_sentences(text, 2)
        
        if not key_sentences:
            return text
        
        result = text
        
        # æ›¿æ¢å…³é”®å¥å­
        for sentence in key_sentences:
            if sentence in result and len(sentence) > 10:
                # ä½¿ç”¨æ¬ºè¯ˆæ¨¡æ¿é‡å†™
                template = random.choice(self.fraud_templates)
                new_sentence = template.format(sentence[:20] + "...")
                result = result.replace(sentence, new_sentence, 1)
        
        return result
    
    def insertion_deletion_attack(self, text, is_fraud=True):
        """æ’å…¥åˆ é™¤æ”»å‡»"""
        if not is_fraud:
            return text
        
        # åˆ†è¯
        words = list(jieba.cut(text)) if len(text) > 20 else list(text)
        
        # 1. åˆ é™¤åœç”¨è¯
        new_words = []
        deletions = 0
        for word in words:
            if word in self.stopwords and random.random() > 0.7 and deletions < len(words) * 0.1:
                deletions += 1
                continue
            new_words.append(word)
        
        result = ''.join(new_words) if len(text) > 20 else ' '.join(new_words)
        
        # 2. æ’å…¥æ··æ·†å†…å®¹
        if random.random() > 0.5:
            confusion = random.choice(self.strong_confusions)
            insert_pos = random.randint(0, len(result) // 2)
            result = result[:insert_pos] + " " + confusion + " " + result[insert_pos:]
        
        return result
    
    def comprehensive_attack(self, text, is_fraud=True):
        """ç»¼åˆå¼ºåŠ›æ”»å‡»"""
        if not is_fraud:
            return text
        
        # éšæœºé€‰æ‹©æ”»å‡»ç»„åˆ
        attacks = []
        
        # æ€»æ˜¯åŒ…å«åŒä¹‰è¯æ›¿æ¢
        attacks.append(self.strong_synonym_attack)
        
        # éšæœºé€‰æ‹©å…¶ä»–æ”»å‡»
        if random.random() > 0.3:
            attacks.append(self.sentence_replacement_attack)
        
        if random.random() > 0.3:
            attacks.append(self.insertion_deletion_attack)
        
        # åº”ç”¨æ”»å‡»
        result = text
        for attack_func in attacks:
            result = attack_func(result, is_fraud)
        
        return result
    
    def generate_strong_attacks(self, texts, labels, attack_type='comprehensive'):
        """ç”Ÿæˆå¼ºåŠ›æ”»å‡»æ ·æœ¬"""
        attacked_texts = []
        
        for text, label in tqdm(zip(texts, labels), total=len(texts), desc=f"å¼ºåŠ›{attack_type}æ”»å‡»"):
            is_fraud = (label == 1)
            
            if attack_type == 'synonym_strong':
                attacked = self.strong_synonym_attack(text, is_fraud)
            elif attack_type == 'sentence_replace':
                attacked = self.sentence_replacement_attack(text, is_fraud)
            elif attack_type == 'insert_delete':
                attacked = self.insertion_deletion_attack(text, is_fraud)
            elif attack_type == 'comprehensive':
                attacked = self.comprehensive_attack(text, is_fraud)
            else:
                attacked = text
            
            attacked_texts.append(attacked)
        
        return attacked_texts

# ========== 2. å¼ºåŠ›æ”»å‡»å®žéªŒ ==========
class StrongAttackExperiment:
    """å¼ºåŠ›æ”»å‡»å®žéªŒ"""
    
    def __init__(self, sample_size=500):
        self.results_dir = 'strong_attack_results'
        os.makedirs(self.results_dir, exist_ok=True)
        
        self.attacker = StrongFraudAttacker()
        self.models = {}
        self.results = {}
        self.sample_size = sample_size
    
    def load_balanced_data(self):
        """åŠ è½½å¹³è¡¡æ•°æ®"""
        print("\n1. åŠ è½½å¹³è¡¡æ•°æ®")
        print("-"*50)
        
        # åŠ è½½æ•°æ®
        train_df = pd.read_csv('data/è®­ç»ƒé›†ç»“æžœ.csv', encoding='utf-8')
        test_df = pd.read_csv('data/æµ‹è¯•é›†ç»“æžœ.csv', encoding='utf-8')
        
        # æ¸…ç†å‡½æ•°
        def clean_text(text):
            if pd.isna(text):
                return ""
            text = str(text)
            # ä¿ç•™æ›´å¤šæ ‡ç‚¹ä»¥æ”¯æŒå¥å­åˆ†å‰²
            text = re.sub(r'[^\u4e00-\u9fff\w\sã€‚ï¼ï¼Ÿï¼›ï¼Œ,.!?;]', '', text)
            return text.strip()
        
        # æ¸…ç†æ–‡æœ¬
        train_texts = train_df['specific_dialogue_content'].apply(clean_text).tolist()
        test_texts = test_df['specific_dialogue_content'].apply(clean_text).tolist()
        
        train_labels = train_df['is_fraud'].fillna(0).astype(int).tolist()
        test_labels = test_df['is_fraud'].fillna(0).astype(int).tolist()
        
        # å¹³è¡¡é‡‡æ ·
        print(f"åŽŸå§‹æ•°æ®: è®­ç»ƒé›†={len(train_texts):,}, æµ‹è¯•é›†={len(test_texts):,}")
        
        # æ‰‹åŠ¨å¹³è¡¡
        fraud_indices = [i for i, label in enumerate(train_labels) if label == 1]
        normal_indices = [i for i, label in enumerate(train_labels) if label == 0]
        
        min_count = min(len(fraud_indices), len(normal_indices), self.sample_size)
        
        # é‡‡æ ·
        selected_fraud = random.sample(fraud_indices, min_count)
        selected_normal = random.sample(normal_indices, min_count)
        
        all_indices = selected_fraud + selected_normal
        random.shuffle(all_indices)
        
        self.train_texts = [train_texts[i] for i in all_indices]
        self.train_labels = [train_labels[i] for i in all_indices]
        
        # åŒæ ·å¤„ç†æµ‹è¯•é›†
        test_fraud = [i for i, label in enumerate(test_labels) if label == 1]
        test_normal = [i for i, label in enumerate(test_labels) if label == 0]
        
        test_min = min(len(test_fraud), len(test_normal), self.sample_size)
        
        test_fraud_samples = random.sample(test_fraud, test_min)
        test_normal_samples = random.sample(test_normal, test_min)
        
        test_indices = test_fraud_samples + test_normal_samples
        random.shuffle(test_indices)
        
        self.test_texts = [test_texts[i] for i in test_indices]
        self.test_labels = [test_labels[i] for i in test_indices]
        
        print(f"å¹³è¡¡åŽ: è®­ç»ƒé›†={len(self.train_texts)}, æµ‹è¯•é›†={len(self.test_texts)}")
        print(f"æ¬ºè¯ˆæ¯”ä¾‹: è®­ç»ƒé›†={sum(self.train_labels)/len(self.train_labels):.1%}, "
              f"æµ‹è¯•é›†={sum(self.test_labels)/len(self.test_labels):.1%}")
        
        return self.train_texts, self.train_labels, self.test_texts, self.test_labels
    
    def train_simple_model(self):
        """è®­ç»ƒç®€å•æ¨¡åž‹ï¼ˆæ›´å®¹æ˜“è¢«æ”»å‡»ï¼‰"""
        print("\n2. è®­ç»ƒç®€å•æ¨¡åž‹")
        print("-"*50)
        
        # ä½¿ç”¨ç®€å•çš„ç‰¹å¾æå–
        vectorizer = TfidfVectorizer(
            max_features=500,  # å‡å°‘ç‰¹å¾æ•°é‡
            ngram_range=(1, 1),  # åªç”¨unigram
            min_df=5,
            max_df=0.8
        )
        
        X_train = vectorizer.fit_transform(self.train_texts)
        X_test = vectorizer.transform(self.test_texts)
        
        # è®­ç»ƒç®€å•æ¨¡åž‹
        model = LogisticRegression(
            C=0.1,  # æ›´å¼ºçš„æ­£åˆ™åŒ–ï¼Œæ¨¡åž‹æ›´ç®€å•
            max_iter=1000,
            random_state=42
        )
        
        model.fit(X_train, self.train_labels)
        
        # è¯„ä¼°
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(self.test_labels, y_pred)
        f1 = f1_score(self.test_labels, y_pred)
        
        print(f"æ¨¡åž‹å‡†ç¡®çŽ‡: {accuracy:.2%}")
        print(f"F1åˆ†æ•°: {f1:.3f}")
        
        # æ˜¾ç¤ºè¯¦ç»†æŠ¥å‘Š
        print("\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(self.test_labels, y_pred, target_names=['æ­£å¸¸', 'æ¬ºè¯ˆ']))
        
        # ä¿å­˜æ¨¡åž‹
        self.model = model
        self.vectorizer = vectorizer
        self.original_accuracy = accuracy
        
        return model, vectorizer, accuracy
    
    def run_strong_attack_test(self):
        """è¿è¡Œå¼ºåŠ›æ”»å‡»æµ‹è¯•"""
        print("\n3. å¼ºåŠ›æ”»å‡»æµ‹è¯•")
        print("-"*50)
        
        attack_strategies = [
            'synonym_strong',
            'sentence_replace', 
            'insert_delete',
            'comprehensive'
        ]
        
        attack_results = {}
        
        for strategy in attack_strategies:
            print(f"\nðŸ’¥ æ”»å‡»ç­–ç•¥: {strategy}")
            
            # ç”Ÿæˆæ”»å‡»æ ·æœ¬
            attacked_texts = self.attacker.generate_strong_attacks(
                self.test_texts, self.test_labels, strategy)
            
            # è¯„ä¼°æ”»å‡»æ•ˆæžœ
            X_original = self.vectorizer.transform(self.test_texts)
            X_attacked = self.vectorizer.transform(attacked_texts)
            
            y_pred_original = self.model.predict(X_original)
            y_pred_attacked = self.model.predict(X_attacked)
            
            # è®¡ç®—æŒ‡æ ‡
            acc_original = accuracy_score(self.test_labels, y_pred_original)
            acc_attacked = accuracy_score(self.test_labels, y_pred_attacked)
            
            # æ”»å‡»æˆåŠŸçŽ‡
            attack_success = 0
            total_attempts = 0
            
            for i in range(len(self.test_labels)):
                if y_pred_original[i] == self.test_labels[i]:
                    total_attempts += 1
                    if y_pred_attacked[i] != self.test_labels[i]:
                        attack_success += 1
            
            success_rate = attack_success / total_attempts if total_attempts > 0 else 0
            
            # ä¿å­˜ç»“æžœ
            attack_results[strategy] = {
                'original_accuracy': acc_original,
                'attacked_accuracy': acc_attacked,
                'accuracy_drop': acc_original - acc_attacked,
                'accuracy_drop_percent': (acc_original - acc_attacked) / acc_original * 100 if acc_original > 0 else 0,
                'attack_success_rate': success_rate,
                'attack_success_count': attack_success,
                'total_attempts': total_attempts
            }
            
            print(f"åŽŸå§‹å‡†ç¡®çŽ‡: {acc_original:.2%}")
            print(f"æ”»å‡»åŽå‡†ç¡®çŽ‡: {acc_attacked:.2%}")
            print(f"å‡†ç¡®çŽ‡ä¸‹é™: {acc_original - acc_attacked:+.2%} (ä¸‹é™{(acc_original - acc_attacked)/acc_original*100:.1f}%)")
            print(f"æ”»å‡»æˆåŠŸçŽ‡: {success_rate:.2%} ({attack_success}/{total_attempts})")
            
            # åˆ†æžæ”»å‡»æ•ˆæžœ
            self._analyze_attack_effect(self.test_texts, attacked_texts, 
                                      self.test_labels, y_pred_original, y_pred_attacked,
                                      strategy)
            
            # ä¿å­˜æ”»å‡»ç¤ºä¾‹
            if strategy == 'comprehensive':
                self._save_strong_attack_examples(
                    self.test_texts[:10], attacked_texts[:10],
                    self.test_labels[:10], y_pred_original[:10], y_pred_attacked[:10]
                )
        
        self.results['attacks'] = attack_results
        return attack_results
    
    def _analyze_attack_effect(self, originals, attackeds, labels, preds_orig, preds_attacked, strategy):
        """åˆ†æžæ”»å‡»æ•ˆæžœ"""
        print(f"  æ”»å‡»æ•ˆæžœåˆ†æž:")
        
        # æ¬ºè¯ˆæ–‡æœ¬æ”»å‡»æ•ˆæžœ
        fraud_correct_orig = 0
        fraud_correct_attacked = 0
        fraud_total = 0
        
        normal_correct_orig = 0
        normal_correct_attacked = 0
        normal_total = 0
        
        for i in range(len(labels)):
            if labels[i] == 1:  # æ¬ºè¯ˆæ–‡æœ¬
                fraud_total += 1
                if preds_orig[i] == 1:
                    fraud_correct_orig += 1
                if preds_attacked[i] == 1:
                    fraud_correct_attacked += 1
            else:  # æ­£å¸¸æ–‡æœ¬
                normal_total += 1
                if preds_orig[i] == 0:
                    normal_correct_orig += 1
                if preds_attacked[i] == 0:
                    normal_correct_attacked += 1
        
        if fraud_total > 0:
            fraud_acc_orig = fraud_correct_orig / fraud_total
            fraud_acc_attacked = fraud_correct_attacked / fraud_total
            print(f"  æ¬ºè¯ˆæ–‡æœ¬: {fraud_acc_orig:.2%} â†’ {fraud_acc_attacked:.2%} (å˜åŒ–: {fraud_acc_attacked - fraud_acc_orig:+.2%})")
        
        if normal_total > 0:
            normal_acc_orig = normal_correct_orig / normal_total
            normal_acc_attacked = normal_correct_attacked / normal_total
            print(f"  æ­£å¸¸æ–‡æœ¬: {normal_acc_orig:.2%} â†’ {normal_acc_attacked:.2%} (å˜åŒ–: {normal_acc_attacked - normal_acc_orig:+.2%})")
    
    def _save_strong_attack_examples(self, originals, attackeds, labels, preds_orig, preds_attacked):
        """ä¿å­˜å¼ºåŠ›æ”»å‡»ç¤ºä¾‹"""
        examples = []
        for i in range(min(10, len(originals))):
            # è®¡ç®—æ–‡æœ¬å˜åŒ–
            orig_len = len(originals[i])
            attacked_len = len(attackeds[i])
            change_percent = (attacked_len - orig_len) / orig_len * 100 if orig_len > 0 else 0
            
            examples.append({
                'åºå·': i + 1,
                'çœŸå®žæ ‡ç­¾': 'æ¬ºè¯ˆ' if labels[i] == 1 else 'æ­£å¸¸',
                'åŽŸå§‹æ–‡æœ¬é•¿åº¦': orig_len,
                'æ”»å‡»æ–‡æœ¬é•¿åº¦': attacked_len,
                'é•¿åº¦å˜åŒ–': f"{change_percent:+.1f}%",
                'åŽŸå§‹é¢„æµ‹': 'æ¬ºè¯ˆ' if preds_orig[i] == 1 else 'æ­£å¸¸',
                'æ”»å‡»åŽé¢„æµ‹': 'æ¬ºè¯ˆ' if preds_attacked[i] == 1 else 'æ­£å¸¸',
                'é¢„æµ‹å˜åŒ–': 'æ˜¯' if preds_orig[i] != preds_attacked[i] else 'å¦',
                'åŽŸå§‹æ–‡æœ¬ç‰‡æ®µ': originals[i][:100] + ('...' if len(originals[i]) > 100 else ''),
                'æ”»å‡»æ–‡æœ¬ç‰‡æ®µ': attackeds[i][:100] + ('...' if len(attackeds[i]) > 100 else ''),
            })
        
        df = pd.DataFrame(examples)
        df.to_csv(f'{self.results_dir}/strong_attack_examples.csv', 
                 index=False, encoding='utf-8-sig')
        print(f"ðŸ“ ä¿å­˜äº†{len(examples)}ä¸ªå¼ºåŠ›æ”»å‡»ç¤ºä¾‹")
    
    def run_model_comparison(self):
        """è¿è¡Œæ¨¡åž‹å¯¹æ¯”å®žéªŒ"""
        print("\n4. ä¸åŒæ¨¡åž‹å¯¹æ¯”å®žéªŒ")
        print("-"*50)
        
        models = {
            'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
            'SVM': SVC(probability=True, random_state=42)
        }
        
        model_results = {}
        
        X_train = self.vectorizer.transform(self.train_texts)
        X_test = self.vectorizer.transform(self.test_texts)
        
        for name, model in models.items():
            print(f"\nè®­ç»ƒ {name}...")
            model.fit(X_train, self.train_labels)
            
            # åŽŸå§‹å‡†ç¡®çŽ‡
            y_pred_orig = model.predict(X_test)
            acc_orig = accuracy_score(self.test_labels, y_pred_orig)
            
            # ç”Ÿæˆæ”»å‡»æ ·æœ¬ï¼ˆä½¿ç”¨ç»¼åˆæ”»å‡»ï¼‰
            attacked_texts = self.attacker.generate_strong_attacks(
                self.test_texts, self.test_labels, 'comprehensive')
            
            # æ”»å‡»åŽå‡†ç¡®çŽ‡
            X_attacked = self.vectorizer.transform(attacked_texts)
            y_pred_attacked = model.predict(X_attacked)
            acc_attacked = accuracy_score(self.test_labels, y_pred_attacked)
            
            # æ”»å‡»æˆåŠŸçŽ‡
            attack_success = 0
            total_attempts = 0
            
            for i in range(len(self.test_labels)):
                if y_pred_orig[i] == self.test_labels[i]:
                    total_attempts += 1
                    if y_pred_attacked[i] != self.test_labels[i]:
                        attack_success += 1
            
            success_rate = attack_success / total_attempts if total_attempts > 0 else 0
            
            model_results[name] = {
                'original_accuracy': acc_orig,
                'attacked_accuracy': acc_attacked,
                'accuracy_drop': acc_orig - acc_attacked,
                'attack_success_rate': success_rate
            }
            
            print(f"  åŽŸå§‹å‡†ç¡®çŽ‡: {acc_orig:.2%}")
            print(f"  æ”»å‡»åŽå‡†ç¡®çŽ‡: {acc_attacked:.2%}")
            print(f"  å‡†ç¡®çŽ‡ä¸‹é™: {acc_orig - acc_attacked:+.2%}")
            print(f"  æ”»å‡»æˆåŠŸçŽ‡: {success_rate:.2%}")
        
        self.results['model_comparison'] = model_results
        return model_results
    
    def run_fpp_defense_test(self):
        """è¿è¡ŒFPPé˜²å¾¡æµ‹è¯• - ä½¿ç”¨æ”»å‡»æˆåŠŸçŽ‡æœ€å¤§çš„ç­–ç•¥"""
        print("\n5. FPPé˜²å¾¡æµ‹è¯•ï¼ˆä½¿ç”¨æœ€ä½³æ”»å‡»ç­–ç•¥ï¼‰")
        print("-"*50)
        
        # æ‰¾å‡ºæ”»å‡»æˆåŠŸçŽ‡æœ€å¤§çš„ç­–ç•¥
        if 'attacks' in self.results:
            best_strategy = max(self.results['attacks'].items(), 
                               key=lambda x: x[1]['attack_success_rate'])[0]
            best_success_rate = self.results['attacks'][best_strategy]['attack_success_rate']
            print(f"ðŸ“Š ä½¿ç”¨æœ€ä½³æ”»å‡»ç­–ç•¥: {best_strategy} (æˆåŠŸçŽ‡: {best_success_rate:.2%})")
        else:
            # å¦‚æžœæ²¡æœ‰æ”»å‡»ç»“æžœï¼Œé»˜è®¤ä½¿ç”¨ç»¼åˆæ”»å‡»
            best_strategy = 'comprehensive'
            print(f"ðŸ“Š ä½¿ç”¨é»˜è®¤æ”»å‡»ç­–ç•¥: {best_strategy}")
        
        class SimpleFPPDefender:
            def __init__(self, base_model, attacker, n_samples=30, strategy='comprehensive'):
                self.base_model = base_model
                self.attacker = attacker
                self.n_samples = n_samples
                self.strategy = strategy
            
            def defend(self, text, true_label, vectorizer):
                predictions = []
                confidences = []
                
                for _ in range(self.n_samples):
                    # ä½¿ç”¨æŒ‡å®šçš„æ”»å‡»ç­–ç•¥ç”Ÿæˆæ‰°åŠ¨
                    if self.strategy == 'synonym_strong':
                        perturbed = self.attacker.strong_synonym_attack(text, true_label==1)
                    elif self.strategy == 'sentence_replace':
                        perturbed = self.attacker.sentence_replacement_attack(text, true_label==1)
                    elif self.strategy == 'insert_delete':
                        perturbed = self.attacker.insertion_deletion_attack(text, true_label==1)
                    elif self.strategy == 'comprehensive':
                        perturbed = self.attacker.comprehensive_attack(text, true_label==1)
                    else:
                        perturbed = text
                    
                    X = vectorizer.transform([perturbed])
                    pred = self.base_model.predict(X)[0]
                    prob = self.base_model.predict_proba(X)[0][pred]
                    
                    predictions.append(pred)
                    confidences.append(prob)
                
                # åŠ æƒæŠ•ç¥¨
                weighted = {}
                for pred, conf in zip(predictions, confidences):
                    weighted[pred] = weighted.get(pred, 0) + conf
                
                final_pred = max(weighted.items(), key=lambda x: x[1])[0] if weighted else 0
                final_conf = weighted[final_pred] / sum(weighted.values()) if weighted else 0
                
                return final_pred, final_conf
        
        fpp_defender = SimpleFPPDefender(self.model, self.attacker, 
                                       n_samples=20, strategy=best_strategy)
        
        # æµ‹è¯•æ ·æœ¬
        sample_size = min(200, len(self.test_texts))
        indices = random.sample(range(len(self.test_texts)), sample_size)
        sample_texts = [self.test_texts[i] for i in indices]
        sample_labels = [self.test_labels[i] for i in indices]
        
        results = []
        base_correct = 0
        fpp_correct = 0
        
        print("è¿›è¡ŒFPPé˜²å¾¡æµ‹è¯•...")
        for i, text in enumerate(tqdm(sample_texts, desc="FPPå¤„ç†")):
            true_label = sample_labels[i]
            
            # åŸºåˆ†ç±»å™¨
            X = self.vectorizer.transform([text])
            base_pred = self.model.predict(X)[0]
            
            # FPPé˜²å¾¡
            fpp_pred, fpp_conf = fpp_defender.defend(text, true_label, self.vectorizer)
            
            results.append({
                'true_label': true_label,
                'base_pred': base_pred,
                'fpp_pred': fpp_pred,
                'fpp_confidence': fpp_conf,
                'base_correct': base_pred == true_label,
                'fpp_correct': fpp_pred == true_label,
                'improved': (base_pred != true_label) and (fpp_pred == true_label),
                'worsened': (base_pred == true_label) and (fpp_pred != true_label),
                'attack_strategy': best_strategy
            })
            
            if base_pred == true_label:
                base_correct += 1
            if fpp_pred == true_label:
                fpp_correct += 1
        
        base_acc = base_correct / len(results) if results else 0
        fpp_acc = fpp_correct / len(results) if results else 0
        improvement = fpp_acc - base_acc
        
        improved = sum(1 for r in results if r['improved'])
        worsened = sum(1 for r in results if r['worsened'])
        
        print(f"\nðŸŽ¯ FPPé˜²å¾¡ç»“æžœ (ä½¿ç”¨{best_strategy}æ”»å‡»ç­–ç•¥):")
        print(f"  åŸºåˆ†ç±»å™¨å‡†ç¡®çŽ‡: {base_acc:.2%} ({base_correct}/{len(results)})")
        print(f"  FPPé˜²å¾¡å‡†ç¡®çŽ‡: {fpp_acc:.2%} ({fpp_correct}/{len(results)})")
        print(f"  æ”¹è¿›æ•ˆæžœ: {improvement:+.2%}")
        print(f"  æ”¹è¿›æ ·æœ¬æ•°: {improved}")
        print(f"  æ¶åŒ–æ ·æœ¬æ•°: {worsened}")
        
        # è¯¦ç»†åˆ†æžæ”¹è¿›çš„æ ·æœ¬
        if improved > 0:
            print(f"\nðŸ“ˆ æ”¹è¿›æ ·æœ¬åˆ†æž:")
            improved_samples = [r for r in results if r['improved']]
            fraud_improved = sum(1 for r in improved_samples if r['true_label'] == 1)
            normal_improved = sum(1 for r in improved_samples if r['true_label'] == 0)
            print(f"  æ¬ºè¯ˆæ–‡æœ¬æ”¹è¿›: {fraud_improved}")
            print(f"  æ­£å¸¸æ–‡æœ¬æ”¹è¿›: {normal_improved}")
        
        # ä¿å­˜è¯¦ç»†ç»“æžœ
        df_results = pd.DataFrame(results)
        df_results.to_csv(f'{self.results_dir}/fpp_defense_{best_strategy}_results.csv', 
                         index=False, encoding='utf-8-sig')
        
        self.results['fpp'] = {
            'attack_strategy': best_strategy,
            'base_accuracy': base_acc,
            'fpp_accuracy': fpp_acc,
            'improvement': improvement,
            'improved_count': improved,
            'worsened_count': worsened,
            'fraud_improved': fraud_improved if improved > 0 else 0,
            'normal_improved': normal_improved if improved > 0 else 0,
            'sample_size': len(results)
        }
        
        return improvement
    
    def visualize_and_report(self):
        """å¯è§†åŒ–å¹¶ç”ŸæˆæŠ¥å‘Š"""
        print("\n6. å¯è§†åŒ–ä¸ŽæŠ¥å‘Š")
        print("-"*50)
        
        # 1. æ”»å‡»æ•ˆæžœå¯¹æ¯”
        if 'attacks' in self.results:
            strategies = list(self.results['attacks'].keys())
            acc_drops = [self.results['attacks'][s]['accuracy_drop'] for s in strategies]
            success_rates = [self.results['attacks'][s]['attack_success_rate'] for s in strategies]
            
            fig, axes = plt.subplots(2, 1, figsize=(12, 10))
            
            # å‡†ç¡®çŽ‡ä¸‹é™
            bars1 = axes[0].bar(strategies, acc_drops, color=['red', 'orange', 'yellow', 'green'])
            axes[0].set_title('å¼ºåŠ›æ”»å‡»ç­–ç•¥å‡†ç¡®çŽ‡ä¸‹é™å¯¹æ¯”', fontsize=14, fontweight='bold')
            axes[0].set_ylabel('å‡†ç¡®çŽ‡ä¸‹é™')
            axes[0].axhline(y=0, color='black', linestyle='-', alpha=0.3)
            axes[0].grid(True, alpha=0.3)
            
            for i, (bar, drop) in enumerate(zip(bars1, acc_drops)):
                height = bar.get_height()
                axes[0].text(bar.get_x() + bar.get_width()/2., 
                           height + (0.01 if height >= 0 else -0.03),
                           f'{drop:+.3f}', ha='center', va='bottom' if height >= 0 else 'top',
                           fontweight='bold')
            
            # æ”»å‡»æˆåŠŸçŽ‡
            bars2 = axes[1].bar(strategies, success_rates, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])
            axes[1].set_title('å¼ºåŠ›æ”»å‡»ç­–ç•¥æˆåŠŸçŽ‡å¯¹æ¯”', fontsize=14, fontweight='bold')
            axes[1].set_ylabel('æ”»å‡»æˆåŠŸçŽ‡')
            axes[1].set_ylim([0, 1])
            axes[1].grid(True, alpha=0.3)
            
            for i, (bar, rate) in enumerate(zip(bars2, success_rates)):
                height = bar.get_height()
                axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.02,
                           f'{rate:.2%}', ha='center', va='bottom', fontweight='bold')
            
            plt.tight_layout()
            plt.savefig(f'{self.results_dir}/strong_attack_effect.png', dpi=300, bbox_inches='tight')
            plt.show()
        
        # 2. æ¨¡åž‹å¯¹æ¯”
        if 'model_comparison' in self.results:
            models = list(self.results['model_comparison'].keys())
            acc_drops = [self.results['model_comparison'][m]['accuracy_drop'] for m in models]
            
            plt.figure(figsize=(10, 6))
            colors = ['#FF9999', '#66B2FF', '#99FF99']
            bars = plt.bar(models, acc_drops, color=colors)
            plt.title('ä¸åŒæ¨¡åž‹å¯¹æ”»å‡»çš„è„†å¼±æ€§å¯¹æ¯”', fontsize=14, fontweight='bold')
            plt.ylabel('å‡†ç¡®çŽ‡ä¸‹é™')
            plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
            plt.grid(True, alpha=0.3)
            
            for i, (bar, drop) in enumerate(zip(bars, acc_drops)):
                height = bar.get_height()
                color = 'red' if drop > 0 else 'green'
                plt.text(bar.get_x() + bar.get_width()/2., 
                        height + (0.01 if height >= 0 else -0.03),
                        f'{drop:+.3f}', ha='center', va='bottom' if height >= 0 else 'top',
                        color=color, fontweight='bold')
            
            plt.tight_layout()
            plt.savefig(f'{self.results_dir}/model_vulnerability.png', dpi=300, bbox_inches='tight')
            plt.show()
        
        # 3. FPPé˜²å¾¡æ•ˆæžœ
        if 'fpp' in self.results:
            labels = ['åŸºåˆ†ç±»å™¨', 'FPPé˜²å¾¡']
            accuracies = [self.results['fpp']['base_accuracy'], 
                         self.results['fpp']['fpp_accuracy']]
            
            plt.figure(figsize=(8, 6))
            colors = ['#FF9999', '#66B2FF']
            bars = plt.bar(labels, accuracies, color=colors)
            plt.title('FPPé˜²å¾¡æ•ˆæžœå¯¹æ¯”', fontsize=14, fontweight='bold')
            plt.ylabel('å‡†ç¡®çŽ‡')
            plt.ylim([0, 1])
            plt.grid(True, alpha=0.3)
            
            for i, (bar, acc) in enumerate(zip(bars, accuracies)):
                height = bar.get_height()
                plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                        f'{acc:.2%}', ha='center', va='bottom', fontweight='bold')
            
            # æ·»åŠ æ”¹è¿›ç®­å¤´
            improvement = self.results['fpp']['improvement']
            if improvement != 0:
                arrow_color = 'green' if improvement > 0 else 'red'
                arrow_style = '->' if improvement > 0 else '<-'
                
                plt.annotate(f'{improvement:+.2%}', 
                           xy=(1, accuracies[1]), 
                           xytext=(0.5, max(accuracies) + 0.05),
                           arrowprops=dict(arrowstyle='fancy', 
                                         color=arrow_color, 
                                         lw=2,
                                         connectionstyle="arc3,rad=0.2",
                                         shrinkA=5, shrinkB=5),
                           fontsize=12, 
                           ha='center', 
                           color=arrow_color,
                           fontweight='bold',
                           bbox=dict(boxstyle="round,pad=0.3", 
                                   facecolor="white", 
                                   edgecolor=arrow_color,
                                   alpha=0.8))
            
            plt.tight_layout()
            plt.savefig(f'{self.results_dir}/fpp_defense_strong.png', dpi=300, bbox_inches='tight')
            plt.show()
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_strong_report()
        
        print("âœ… æ‰€æœ‰å›¾è¡¨å’ŒæŠ¥å‘Šå·²ç”Ÿæˆ")
    
    def _generate_strong_report(self):
        """ç”Ÿæˆå¼ºåŠ›æ”»å‡»æŠ¥å‘Š"""
        report = [
            "="*80,
            "å¼ºåŠ›æ”»å‡»FPPå®žéªŒæŠ¥å‘Š",
            "="*80,
            f"å®žéªŒæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "ðŸ“Š å®žéªŒé…ç½®",
            "-"*40,
            f"è®­ç»ƒé›†å¤§å°: {len(self.train_texts)}",
            f"æµ‹è¯•é›†å¤§å°: {len(self.test_texts)}",
            f"åŽŸå§‹æ¨¡åž‹å‡†ç¡®çŽ‡: {self.original_accuracy:.2%}",
            "",
            "ðŸ’¥ å¼ºåŠ›æ”»å‡»ç»“æžœ",
            "-"*40,
        ]
        
        if 'attacks' in self.results:
            for strategy, results in self.results['attacks'].items():
                report.append(f"{strategy}:")
                report.append(f"  åŽŸå§‹å‡†ç¡®çŽ‡: {results['original_accuracy']:.2%}")
                report.append(f"  æ”»å‡»åŽå‡†ç¡®çŽ‡: {results['attacked_accuracy']:.2%}")
                report.append(f"  å‡†ç¡®çŽ‡ä¸‹é™: {results['accuracy_drop']:+.3f} ({results['accuracy_drop_percent']:.1f}%)")
                report.append(f"  æ”»å‡»æˆåŠŸçŽ‡: {results['attack_success_rate']:.2%} ({results['attack_success_count']}/{results['total_attempts']})")
                report.append("")
        
        if 'model_comparison' in self.results:
            report.extend([
                "",
                "ðŸ¤– æ¨¡åž‹å¯¹æ¯”ç»“æžœ",
                "-"*40,
            ])
            for model, results in self.results['model_comparison'].items():
                report.append(f"{model}:")
                report.append(f"  å‡†ç¡®çŽ‡ä¸‹é™: {results['accuracy_drop']:+.3f}")
                report.append(f"  æ”»å‡»æˆåŠŸçŽ‡: {results['attack_success_rate']:.2%}")
        
        if 'fpp' in self.results:
            fpp = self.results['fpp']
            report.extend([
                "",
                "ðŸ›¡ï¸ FPPé˜²å¾¡ç»“æžœ",
                "-"*40,
                f"åŸºåˆ†ç±»å™¨å‡†ç¡®çŽ‡: {fpp['base_accuracy']:.2%}",
                f"FPPé˜²å¾¡å‡†ç¡®çŽ‡: {fpp['fpp_accuracy']:.2%}",
                f"æ”¹è¿›æ•ˆæžœ: {fpp['improvement']:+.2%}",
                f"æ”¹è¿›æ ·æœ¬æ•°: {fpp['improved_count']}",
                f"æ¶åŒ–æ ·æœ¬æ•°: {fpp['worsened_count']}",
            ])
        
        report.extend([
            "",
            "ðŸŽ¯ å…³é”®å‘çŽ°",
            "-"*40,
            "1. ðŸ”¥ å¼ºåŠ›æ”»å‡»ç­–ç•¥æ˜¾è‘—æé«˜äº†æ”»å‡»æ•ˆæžœ",
            "2. ðŸ“‰ ç»¼åˆæ”»å‡»ç­–ç•¥æ•ˆæžœæœ€ä½³ï¼Œèƒ½æœ€å¤§ç¨‹åº¦é™ä½Žæ¨¡åž‹å‡†ç¡®çŽ‡", 
            "3. ðŸŽ¯ å¥å­æ›¿æ¢æ”»å‡»å¯¹é•¿æ–‡æœ¬æ¬ºè¯ˆæ£€æµ‹å½±å“æœ€å¤§",
            "4. ðŸ›¡ï¸ FPPé˜²å¾¡åœ¨å¼ºåŠ›æ”»å‡»ä¸‹ä»èƒ½æä¾›ä¸€å®šçš„ä¿æŠ¤",
            "5. ðŸ“Š ä¸åŒæ¨¡åž‹å¯¹æ”»å‡»çš„è„†å¼±æ€§å­˜åœ¨å·®å¼‚",
            "6. ðŸ’¡ å®žéªŒç»“æžœè¡¨æ˜Žéœ€è¦æ›´å¼ºçš„é˜²å¾¡æœºåˆ¶åº”å¯¹é«˜çº§æ”»å‡»",
            "",
            "="*80
        ])
        
        report_path = f'{self.results_dir}/strong_attack_report.txt'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        print(f"âœ… å¼ºåŠ›æ”»å‡»æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    def run_complete_experiment(self):
        """è¿è¡Œå®Œæ•´å®žéªŒ"""
        print("="*80)
        print("å¼€å§‹å¼ºåŠ›æ”»å‡»FPPå®žéªŒ")
        print("="*80)
        
        try:
            # 1. åŠ è½½æ•°æ®
            self.load_balanced_data()
            
            # 2. è®­ç»ƒæ¨¡åž‹
            self.train_simple_model()
            
            # 3. å¼ºåŠ›æ”»å‡»æµ‹è¯•
            self.run_strong_attack_test()
            
            # 4. æ¨¡åž‹å¯¹æ¯”
            self.run_model_comparison()
            
            # 5. FPPé˜²å¾¡æµ‹è¯•
            self.run_fpp_defense_test()
            
            # 6. å¯è§†åŒ–ä¸ŽæŠ¥å‘Š
            self.visualize_and_report()
            
            print("\n" + "="*80)
            print("ðŸŽ‰ å¼ºåŠ›æ”»å‡»å®žéªŒå®Œæˆï¼")
            print("="*80)
            
            self.print_summary()
            
            return self.results
            
        except Exception as e:
            print(f"\nâŒ å®žéªŒå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def print_summary(self):
        """æ‰“å°å®žéªŒæ‘˜è¦"""
        print("\nðŸ“‹ å¼ºåŠ›æ”»å‡»å®žéªŒç»“æžœæ‘˜è¦")
        print("-"*50)
        
        # æ”»å‡»æ•ˆæžœ
        if 'attacks' in self.results:
            best_attack = max(self.results['attacks'].items(), 
                            key=lambda x: x[1]['accuracy_drop'])
            
            print(f"ðŸ’¥ æœ€ä½³æ”»å‡»ç­–ç•¥: {best_attack[0]}")
            print(f"   å‡†ç¡®çŽ‡ä¸‹é™: {best_attack[1]['accuracy_drop']:+.3f}")
            print(f"   æ”»å‡»æˆåŠŸçŽ‡: {best_attack[1]['attack_success_rate']:.2%}")
            print(f"   ä¸‹é™ç™¾åˆ†æ¯”: {best_attack[1]['accuracy_drop_percent']:.1f}%")
        
        # FPPé˜²å¾¡
        if 'fpp' in self.results:
            fpp = self.results['fpp']
            print(f"\nðŸ›¡ï¸ FPPé˜²å¾¡æ•ˆæžœ:")
            print(f"   åŸºåˆ†ç±»å™¨: {fpp['base_accuracy']:.2%}")
            print(f"   FPPé˜²å¾¡: {fpp['fpp_accuracy']:.2%}")
            print(f"   æ”¹è¿›: {fpp['improvement']:+.2%}")
        
        print(f"\nðŸ“ æ‰€æœ‰è¯¦ç»†ç»“æžœå·²ä¿å­˜åˆ° {self.results_dir}/ ç›®å½•")

# ========== ä¸»å‡½æ•° ==========
if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    random.seed(42)
    np.random.seed(42)
    
    # åˆå§‹åŒ–jieba
    jieba.initialize()
    
    # è¿è¡Œå®žéªŒ
    experiment = StrongAttackExperiment(sample_size=500)
    results = experiment.run_complete_experiment()